{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Demo with telegram data\n",
    "\n",
    "This notebook demonstrates the usage of langchain integrated with chromadb. \n",
    "\n",
    "The telegram extracted messages are embedded using openAI. The embeddings are saved to chromadb locally and then used for semantic search and RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "from langchain.llms import OpenAIChat\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from IPython.display import display, Markdown\n",
    "from telethon.sync import TelegramClient\n",
    "from telethon.tl.types import InputMessagesFilterEmpty\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing\n",
    "\n",
    "Load telegram data for a specific channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_id = os.environ[\"TELEGRAM_API_ID\"]\n",
    "api_hash = os.environ[\"TELEGRAM_API_HASH\"]\n",
    "pinecone_key = os.environ[\"PINECONE_APIKEY\"]\n",
    "phone = os.environ[\"TELEGRAM_PHONE\"]\n",
    "username = os.environ[\"TELEGRAM_USERNAME\"]\n",
    "messages = []\n",
    "\n",
    "channel_id = \"singularitynet\"\n",
    "\n",
    "pd_data = []\n",
    "\n",
    "columns = [\"channel_name\", \"id\", \"peer_id\", \"date\", \"message\", \"out\", \"mentioned\",\n",
    "        \"media_unread\", \"silent\", \"post\", \"from_scheduled\", \"legacy\", \n",
    "        \"edit_hide\", \"pinned\",\"noforwards\", \"from_id\", \"fwd_from\", \"via_bot_id\",\n",
    "        \"reply_to\", \"media\", \"reply_markup\", \"entities\", \"views\",\n",
    "        \"forwards\", \"replies\", \"edit_date\", \"post_author\", \"grouped_id\",\n",
    "        \"reactions\", \"restriction_reason\", \"ttl_period\"]\n",
    "\n",
    "client = TelegramClient(f\"../sessions_data/{phone}\", api_id, api_hash)\n",
    "channel_id = \"singularitynet\"\n",
    "n = 20000\n",
    "\n",
    "async with client:        \n",
    "    async for msg in client.iter_messages(channel_id, filter=InputMessagesFilterEmpty, limit=n):\n",
    "        try:\n",
    "            pd_data.append((channel_id, msg.id, msg.peer_id, msg.date, msg.message,\n",
    "                    msg.out, msg.mentioned, msg.media_unread, msg.silent,msg.post,\n",
    "                    msg.from_scheduled, msg.legacy, msg.edit_hide, msg.pinned, msg.noforwards,\n",
    "                    msg.from_id.user_id if hasattr(msg.from_id, \"user_id\") else msg.from_id.channel_id, msg.fwd_from, msg.via_bot_id, msg.reply_to, msg.media, msg.reply_markup,\n",
    "                    msg.entities, msg.views, msg.forwards, msg.replies, msg.edit_date, msg.post_author,\n",
    "                    msg.grouped_id, msg.reactions, msg.restriction_reason, msg.ttl_period\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(msg.from_id)\n",
    "            break\n",
    "\n",
    "df = pd.DataFrame(pd_data, columns=columns)\n",
    "df = df[df['message'] != ''] # remove empty messages\n",
    "df = df[~df[\"message\"].isna()] # remove nan text\n",
    "df = df.sort_values(by=\"date\", ascending=False)\n",
    "df = df.set_index([\"channel_name\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>peer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>out</th>\n",
       "      <th>mentioned</th>\n",
       "      <th>media_unread</th>\n",
       "      <th>silent</th>\n",
       "      <th>post</th>\n",
       "      <th>from_scheduled</th>\n",
       "      <th>legacy</th>\n",
       "      <th>...</th>\n",
       "      <th>entities</th>\n",
       "      <th>views</th>\n",
       "      <th>forwards</th>\n",
       "      <th>replies</th>\n",
       "      <th>edit_date</th>\n",
       "      <th>post_author</th>\n",
       "      <th>grouped_id</th>\n",
       "      <th>reactions</th>\n",
       "      <th>restriction_reason</th>\n",
       "      <th>ttl_period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_name</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">singularitynet</th>\n",
       "      <th>1007934</th>\n",
       "      <td>PeerChannel(channel_id=1140090881)</td>\n",
       "      <td>2024-04-29 08:20:04+00:00</td>\n",
       "      <td>‍Welcome Do,\\nJoin us on the journey towards A...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[MessageEntityTextUrl(offset=0, length=1, url=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReplies(replies=0, replies_pts=1423094,...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007933</th>\n",
       "      <td>PeerChannel(channel_id=1140090881)</td>\n",
       "      <td>2024-04-29 07:55:54+00:00</td>\n",
       "      <td>No, that wont be possible</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   peer_id  \\\n",
       "channel_name   id                                            \n",
       "singularitynet 1007934  PeerChannel(channel_id=1140090881)   \n",
       "               1007933  PeerChannel(channel_id=1140090881)   \n",
       "\n",
       "                                            date  \\\n",
       "channel_name   id                                  \n",
       "singularitynet 1007934 2024-04-29 08:20:04+00:00   \n",
       "               1007933 2024-04-29 07:55:54+00:00   \n",
       "\n",
       "                                                                  message  \\\n",
       "channel_name   id                                                           \n",
       "singularitynet 1007934  ‍Welcome Do,\\nJoin us on the journey towards A...   \n",
       "               1007933                          No, that wont be possible   \n",
       "\n",
       "                          out  mentioned  media_unread  silent   post  \\\n",
       "channel_name   id                                                       \n",
       "singularitynet 1007934  False      False         False    True  False   \n",
       "               1007933  False      False         False   False  False   \n",
       "\n",
       "                       from_scheduled  legacy  ...  \\\n",
       "channel_name   id                              ...   \n",
       "singularitynet 1007934          False   False  ...   \n",
       "               1007933          False   False  ...   \n",
       "\n",
       "                                                                 entities  \\\n",
       "channel_name   id                                                           \n",
       "singularitynet 1007934  [MessageEntityTextUrl(offset=0, length=1, url=...   \n",
       "               1007933                                               None   \n",
       "\n",
       "                       views forwards  \\\n",
       "channel_name   id                       \n",
       "singularitynet 1007934   NaN      NaN   \n",
       "               1007933   NaN      NaN   \n",
       "\n",
       "                                                                  replies  \\\n",
       "channel_name   id                                                           \n",
       "singularitynet 1007934  MessageReplies(replies=0, replies_pts=1423094,...   \n",
       "               1007933                                               None   \n",
       "\n",
       "                       edit_date  post_author grouped_id reactions  \\\n",
       "channel_name   id                                                    \n",
       "singularitynet 1007934       NaT         None        NaN      None   \n",
       "               1007933       NaT         None        NaN      None   \n",
       "\n",
       "                       restriction_reason ttl_period  \n",
       "channel_name   id                                     \n",
       "singularitynet 1007934               None       None  \n",
       "               1007933               None       None  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total messages: 19559\n",
      "Maximum Date: 2024-04-29 08:20:04+00:00\n",
      "Minimum Date: 2024-03-02 20:12:11+00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Total messages:\", len(df))\n",
    "max_date = df['date'].max()\n",
    "min_date = df['date'].min()\n",
    "print(\"Maximum Date:\", max_date)\n",
    "print(\"Minimum Date:\", min_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for each message in the dataset, create a historical conversation that chains each of the previous replies.\n",
    "\n",
    "Having conversations instead of single messages may provide better context when for LLMS when asking questions about the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def extract_reply_id(val):\n",
    "    \"\"\" search for the matching id\n",
    "    \"\"\"\n",
    "    if isinstance(val, str):\n",
    "        match = re.search(r'reply_to_msg_id=(\\d+)', val)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def compute_message_historical(df):\n",
    "    # compute message history for each message if available\n",
    "\n",
    "    df_extended = df.copy()\n",
    "    df_extended[\"in_history\"] = False\n",
    "    df_extended[\"reply_to_msg_id\"] = df_extended[\"reply_to\"].apply(lambda x: int(x.reply_to_msg_id) if x is not None else None)\n",
    "\n",
    "    # Only use if Class was parsed from text\n",
    "    # df['reply_to_msg_id'] = df['reply_to'].apply(extract_reply_id)\n",
    "    \n",
    "    for (channel_name, message_id), row in df_extended.iterrows():\n",
    "        history = [f\"User_{row['from_id']}: {row['message']}\"] # Initialize historical with current message\n",
    "        reply_id = row[\"reply_to_msg_id\"]\n",
    "        \n",
    "        try:\n",
    "            while not np.isnan(reply_id) and (channel_name, reply_id) in df_extended.index:\n",
    "                # Get reply row\n",
    "                reply_row = df_extended.loc[(channel_name, reply_id)]\n",
    "\n",
    "                # Update history\n",
    "                history.append(f\"User_{reply_row['from_id']}: {reply_row['message']}\")\n",
    "\n",
    "                # # Delete message appended to history\n",
    "                # df_extended = df_extended.drop((channel_name, reply_id))\n",
    "                df_extended.loc[(channel_name, reply_id), \"included\"] = True \n",
    "\n",
    "                # assign next reply id\n",
    "                reply_id = reply_row[\"reply_to_msg_id\"]\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(type(reply_id))\n",
    "            print(\"something failed\", e)\n",
    "\n",
    "        df_extended.loc[(channel_name, message_id), \"history\"] = str(history[::-1])\n",
    "\n",
    "        # Ignore already iterated replies\n",
    "\n",
    "    df_extended[\"history\"] = df_extended[\"history\"].apply(ast.literal_eval)\n",
    "    df_extended[\"history_str\"] = df_extended[\"history\"].apply(lambda x: \"- \" + \"\\n- \".join(x))\n",
    "    df_extended[\"thread_length\"] = df_extended[\"history\"].str.len()\n",
    "    return df_extended\n",
    "\n",
    "df_plus = compute_message_historical(df)\n",
    "df_plus = df_plus[df_plus[\"included\"].isna()]\n",
    "df_plus.to_csv(f\"data/{channel_id}_replies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    - User_210944655: ‍Welcome Do,\\nJoin us on the...\n",
       "1    - User_578573938: waiting to see if agix stake...\n",
       "2    - User_210944655: ⚠️ Safety Warning ‼️ \\n\\n‼️ ...\n",
       "3    - User_6273725083: Hi Guys! Can I please ask s...\n",
       "Name: history_str, dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"data/{channel_id}_replies.csv\")\n",
    "              \n",
    "# Use langchain wrapper to load dataframe              \n",
    "df_loader = DataFrameLoader(df, page_content_column=\"history_str\")\n",
    "docs = df_loader.load()\n",
    "df[\"history_str\"].iloc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11632, 35)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local chroma db for text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to delete  Collection openai_embeddings_singularitynet does not exist.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "\n",
    "CLEAR_COLLECTION = True\n",
    "\n",
    "if CLEAR_COLLECTION:\n",
    "    try:\n",
    "        persistent_client.delete_collection(f\"openai_embeddings_{channel_id}\")\n",
    "        print(\"deleted collection for\", channel_id)\n",
    "    except Exception as e:\n",
    "        print(\"unable to delete \", e)\n",
    "\n",
    "# How to create a client with reset allowed\n",
    "# client = chromadb.HttpClient(settings=Settings(allow_reset=True))\n",
    "# client.reset()  # resets the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our loaded collection of telegram messages, it is time to create embeddings using openAI. Chroma db offers us a simple way to achieve this.\n",
    "\n",
    "Beware! This code performs several request to the openai API in order to create embeddings for each of each message in `docs`. Depending on the size of your dataset, this could incurre in high costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embeddings_function = OpenAIEmbeddings()\n",
    "\n",
    "openai_chroma_client = Chroma.from_documents(\n",
    "    docs, \n",
    "    openai_embeddings_function, \n",
    "    client=persistent_client, \n",
    "    collection_name = f\"openai_embeddings_{channel_id}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic search\n",
    "\n",
    "For simple semantic search, a given a user query is embedded and compared to the most similar items in the local db. This returns the most relevant items of our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to perform similarity search\n",
    "def search_db(db_client, query: str, top_k = 100):\n",
    "    docs = db_client.similarity_search(query, k=top_k)\n",
    "\n",
    "    # print results\n",
    "    for i, item in enumerate(docs[:5]):\n",
    "        print(\"\\nThread\", i)\n",
    "        print(f\"\\n{item.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings are saved locally. Now we can perform search queries by obtaining the most similar documents to our query in order of relevance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thread 0\n",
      "\n",
      "- User_6962443130: Where i can buy this token\n",
      "- User_6859650518: you can buy on the site\n",
      "\n",
      "Thread 1\n",
      "\n",
      "- User_445927377: When we can buy token.\n",
      "\n",
      "Thread 2\n",
      "\n",
      "- User_1836130981: We want to do a deal you have your token fet have their token you need a way to trade\n",
      "\n",
      "Thread 3\n",
      "\n",
      "- User_1174250068: Where do you have to exchange the tokens?\n",
      "\n",
      "Thread 4\n",
      "\n",
      "- User_6962443130: Where i can buy this token\n",
      "- User_6859650518: pm i will put you through with screenshot\n"
     ]
    }
   ],
   "source": [
    "query = \"buy token\"\n",
    "search_db(openai_chroma_client, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval augmented generation\n",
    "\n",
    "For Retrieval augmented generation we make use of Langchain. We pass it the chromadb collection with the embeddings and an user query. Using openAI chat model in the background, it will answer the user query based on the top most relevant results found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=openai_chroma_client.as_retriever(search_type=\"mmr\", search_kwargs={'fetch_k': 30}), \n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are some use cases of singularity net?\"\n",
    "response = qa({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are some use cases of singularity net?',\n",
       " 'result': 'SingularityNet aims to provide a decentralized marketplace for AI services and algorithms. Some potential use cases include healthcare diagnostics, financial analysis, autonomous vehicles, personalized recommendations, and more. The platform enables developers to create and monetize AI services, opening up possibilities for various industries to leverage AI technology.',\n",
       " 'source_documents': [Document(page_content='- User_1922071887: SingularityNet brings a fleet of partner projects and close tie-ins that are being architected to work seamlessly together and create synergies', metadata={'date': '2024-03-29 18:58:25+00:00', 'edit_date': '2024-03-29 18:59:12+00:00', 'edit_hide': True, 'from_id': 1922071887, 'from_scheduled': False, 'history': \"['User_1922071887: SingularityNet brings a fleet of partner projects and close tie-ins that are being architected to work seamlessly together and create synergies']\", 'in_history': False, 'legacy': False, 'media_unread': False, 'mentioned': False, 'message': 'SingularityNet brings a fleet of partner projects and close tie-ins that are being architected to work seamlessly together and create synergies', 'noforwards': False, 'out': False, 'peer_id': 'PeerChannel(channel_id=1140090881)', 'pinned': False, 'post': False, 'reactions': \"MessageReactions(results=[ReactionCount(reaction=ReactionEmoji(emoticon='🙏'), count=2, chosen_order=None)], min=False, can_see_list=True, reactions_as_tags=False, recent_reactions=[MessagePeerReaction(peer_id=PeerUser(user_id=1046975995), date=datetime.datetime(2024, 3, 29, 19, 0, 54, tzinfo=datetime.timezone.utc), reaction=ReactionEmoji(emoticon='🙏'), big=False, unread=False, my=False), MessagePeerReaction(peer_id=PeerUser(user_id=5583737902), date=datetime.datetime(2024, 3, 29, 18, 59, 12, tzinfo=datetime.timezone.utc), reaction=ReactionEmoji(emoticon='🙏'), big=False, unread=False, my=False)])\", 'replies': 'MessageReplies(replies=0, replies_pts=1423094, comments=False, recent_repliers=[], channel_id=None, max_id=None, read_max_id=None)', 'silent': False, 'thread_length': 1}),\n",
       "  Document(page_content='- User_199769265: because I want to know how they appear to be using the original singularitynet domain\\n- User_1285288659: It was a disguised link to a devnet bshit website', metadata={'date': '2024-03-06 11:51:57+00:00', 'edit_hide': False, 'from_id': 1285288659, 'from_scheduled': False, 'history': \"['User_199769265: because I want to know how they appear to be using the original singularitynet domain', 'User_1285288659: It was a disguised link to a devnet bshit website']\", 'in_history': False, 'legacy': False, 'media_unread': False, 'mentioned': False, 'message': 'It was a disguised link to a devnet bshit website', 'noforwards': False, 'out': False, 'peer_id': 'PeerChannel(channel_id=1140090881)', 'pinned': False, 'post': False, 'reply_to': 'MessageReplyHeader(reply_to_scheduled=False, forum_topic=False, quote=False, reply_to_msg_id=975792, reply_to_peer_id=None, reply_from=None, reply_media=None, reply_to_top_id=None, quote_text=None, quote_entities=[], quote_offset=None)', 'reply_to_msg_id': 975792.0, 'silent': False, 'thread_length': 2}),\n",
       "  Document(page_content='- User_982063667: In the technical Tuesday video, Alex said «\\xa0don’t expect too much about Hyperon alpha release\\xa0»\\nHence the question : when do we plan to showcase the power of Hyperon in a real world use case ? \\nI mean, if we want to promote Singularitynet to the world (and not only to devs/tech-savvy/geeks), we need to bring ´this revolutionary’ tech to the ordinary people. \\nWe were lucky so far to get a boost from ChatGPT, SORA and NVIDIA, but that’s only hype and vanish with time.\\nI have the feeling we are ever delaying products launch because the techno is never ready. I get it, given the complexity of the framework. \\nBUT still, wouldn’t it be strategically smart to build and share in the blockchain community a powered AI Dapp or any tangible product, in the meanwhile continuing \\ndeveloping Hyperon? And I am not talking about spin offs. Sure SingularityNet has the talent and manpower to do this ! \\nI have no idea actually about such a product but the thing is, other AI cryptos projects are launching products and benefits from this wave.', metadata={'date': '2024-03-21 12:12:15+00:00', 'edit_date': '2024-03-22 07:54:14+00:00', 'edit_hide': True, 'from_id': 982063667, 'from_scheduled': False, 'history': \"['User_982063667: In the technical Tuesday video, Alex said «\\\\xa0don’t expect too much about Hyperon alpha release\\\\xa0»\\\\nHence the question : when do we plan to showcase the power of Hyperon in a real world use case ? \\\\nI mean, if we want to promote Singularitynet to the world (and not only to devs/tech-savvy/geeks), we need to bring ´this revolutionary’ tech to the ordinary people. \\\\nWe were lucky so far to get a boost from ChatGPT, SORA and NVIDIA, but that’s only hype and vanish with time.\\\\nI have the feeling we are ever delaying products launch because the techno is never ready. I get it, given the complexity of the framework. \\\\nBUT still, wouldn’t it be strategically smart to build and share in the blockchain community a powered AI Dapp or any tangible product, in the meanwhile continuing \\\\ndeveloping Hyperon? And I am not talking about spin offs. Sure SingularityNet has the talent and manpower to do this ! \\\\nI have no idea actually about such a product but the thing is, other AI cryptos projects are launching products and benefits from this wave.']\", 'in_history': False, 'legacy': False, 'media_unread': False, 'mentioned': False, 'message': 'In the technical Tuesday video, Alex said «\\xa0don’t expect too much about Hyperon alpha release\\xa0»\\nHence the question : when do we plan to showcase the power of Hyperon in a real world use case ? \\nI mean, if we want to promote Singularitynet to the world (and not only to devs/tech-savvy/geeks), we need to bring ´this revolutionary’ tech to the ordinary people. \\nWe were lucky so far to get a boost from ChatGPT, SORA and NVIDIA, but that’s only hype and vanish with time.\\nI have the feeling we are ever delaying products launch because the techno is never ready. I get it, given the complexity of the framework. \\nBUT still, wouldn’t it be strategically smart to build and share in the blockchain community a powered AI Dapp or any tangible product, in the meanwhile continuing \\ndeveloping Hyperon? And I am not talking about spin offs. Sure SingularityNet has the talent and manpower to do this ! \\nI have no idea actually about such a product but the thing is, other AI cryptos projects are launching products and benefits from this wave.', 'noforwards': False, 'out': False, 'peer_id': 'PeerChannel(channel_id=1140090881)', 'pinned': False, 'post': False, 'reactions': \"MessageReactions(results=[ReactionCount(reaction=ReactionEmoji(emoticon='👌'), count=1, chosen_order=None)], min=False, can_see_list=True, reactions_as_tags=False, recent_reactions=[MessagePeerReaction(peer_id=PeerUser(user_id=294283697), date=datetime.datetime(2024, 3, 22, 7, 54, 14, tzinfo=datetime.timezone.utc), reaction=ReactionEmoji(emoticon='👌'), big=False, unread=False, my=False)])\", 'replies': 'MessageReplies(replies=0, replies_pts=1423095, comments=False, recent_repliers=[], channel_id=None, max_id=None, read_max_id=None)', 'silent': False, 'thread_length': 1}),\n",
       "  Document(page_content='- User_7078951140: what wallets do you use that can buy and sell singularity easily?', metadata={'date': '2024-03-15 22:20:46+00:00', 'edit_hide': False, 'from_id': 7078951140, 'from_scheduled': False, 'history': \"['User_7078951140: what wallets do you use that can buy and sell singularity easily?']\", 'in_history': False, 'legacy': False, 'media_unread': False, 'mentioned': False, 'message': 'what wallets do you use that can buy and sell singularity easily?', 'noforwards': False, 'out': False, 'peer_id': 'PeerChannel(channel_id=1140090881)', 'pinned': False, 'post': False, 'replies': 'MessageReplies(replies=0, replies_pts=1423095, comments=False, recent_repliers=[], channel_id=None, max_id=None, read_max_id=None)', 'silent': False, 'thread_length': 1})]}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingularityNet aims to provide a decentralized marketplace for AI services and algorithms. Some\n",
      "potential use cases include healthcare diagnostics, financial analysis, autonomous vehicles,\n",
      "personalized recommendations, and more. The platform enables developers to create and monetize AI\n",
      "services, opening up possibilities for various industries to leverage AI technology.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# Wrap the text to a specific width\n",
    "wrapped_text = textwrap.fill(response[\"result\"], width=100)\n",
    "\n",
    "# Print the wrapped text\n",
    "print(wrapped_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the previous response was not prompted specifically to answer questions based on the provided context. So the LLM is making up the answer based on its knwoledge of the world and not on the information provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing persisted chroma collection\n",
    "\n",
    "To rerun the previous code without having to compute embeddings again, we can access the previously saved local chromadb collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11632"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the existing collection has documents\n",
    "collection_name = f\"openai_embeddings_{channel_id}\"\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "collection = persistent_client.get_collection(collection_name)\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings from disk\n",
    "\n",
    "openai_embeddings_function = OpenAIEmbeddings()\n",
    "\n",
    "openai_client = Chroma(\n",
    "    persist_directory=\"./chroma\", \n",
    "    collection_name=collection_name, \n",
    "    embedding_function=openai_embeddings_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that document embeddings were properly loaded by doing a simply similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thread 0\n",
      "\n",
      "- User_339022103: FUD?\n",
      "\n",
      "Thread 1\n",
      "\n",
      "- User_339022103: Your FUD is also rushed\n",
      "- User_551595722: No fud. A pretty direct recommendation to vote against\n",
      "- User_6093679747: This failing is the biggest fud imaginable. FUD hopes to wreck bags. A no vote is guaranteed to.\n",
      "\n",
      "Thread 2\n",
      "\n",
      "- User_417019065: More fudders than ppl in this room\n",
      "- User_1084633296: Definitions are dying in here 😂now: FUD = doesn't agree with what I think\n",
      "- User_1990833629: Soon we will call it \"treason\" and send people to a digital gulag xD\n",
      "\n",
      "Thread 3\n",
      "\n",
      "- User_417019065: More fudders than ppl in this room\n",
      "- User_1084633296: Definitions are dying in here 😂now: FUD = doesn't agree with what I think\n",
      "- User_417019065: Honestly a lot of ppl doesnt know what they are talking seems like they are sheeps lol\n",
      "- User_1990833629: \"Sheep\" goes both ways\n",
      "- User_417019065: Keep crying\n",
      "- User_1990833629: Why do you come here just to troll?\n",
      "\n",
      "Thread 4\n",
      "\n",
      "- User_1922071887: all fair questions\n",
      "- User_5977890525: If you ask these questions in $FET chat, you will probably be banned for FUD.\n"
     ]
    }
   ],
   "source": [
    "query = \"FUD\"\n",
    "search_db(openai_chroma_client, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval with context\n",
    "\n",
    "In this example, we provide an additional prompt to the RetrievalQA Chain. In this prompt, it is indicated that the user query should be answered based only on the given context. The chain is also configured to output every step of its process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the chat model to answer the user query given a context.\n",
    "\n",
    "template= \"\"\"\n",
    "The context given are several messages retrieved from a chat about a blockchain project. Based on those messages try to answer the user question.\n",
    "----------------\n",
    "context: {context}\n",
    "user question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=openai_client.as_retriever(search_type=\"mmr\", search_kwargs={'k': 20}),\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\":True,\n",
    "        \"prompt\": PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let´s explore the prompt structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template='\\nThe context given are several messages retrieved from a chat about a blockchain project. Based on those messages try to answer the user question.\\n----------------\\ncontext: {context}\\nuser question: {question}\\n'\n"
     ]
    }
   ],
   "source": [
    "print(qa.combine_documents_chain.llm_chain.prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now it is time to test with real queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The context given are several messages retrieved from a chat about a blockchain project. Based on those messages try to answer the user question.\n",
      "----------------\n",
      "context: - User_5583737902: Another reason why presenting the case as a done deal before a vote is bad. It puts too much pressure on the project if a NO is passed.\n",
      "\n",
      "- User_6165637792: What a way to ruin such a great project\n",
      "\n",
      "- User_1086637470: Why I shall vote NO:\n",
      "\n",
      "1. Rushed vote with WP non-present with enough time before vote to have a healthy debate. Remember: business intelligence tactics include things like this. Quick poorly informed false dicotomies presented as opportunities with time-pressure inciting to FOMO. Classic marketing /sales tactics.\n",
      "2. The feeling that this prssure comes from an urge imposed by FETCH AI plans.\n",
      "3. Badly negotiated deal  to say least.\n",
      "4. Imposing a change of token to holders that modifies previous compromises in SNET ecosystem.\n",
      "5. This token changes will imply i)gas expenditure, ii)tax problems as it is an effective ptlatromonial change, iii) other consequences regarding token utility, staking benefits, airdrops for phase 2 spinoffs and so on. iv) unforeseen consequences.\n",
      "6. Bad image created for a community that either only thinks how fetchai bullrun can benefit ASI token price or that does not believe enough in vision SNET to stay engaged with the course of action AGIX. Or both at the same time. This is a display of project weakness.\n",
      "7. The fact that the SNET team discards the possibility of renegotation of terms after a putative NO victory, display a weak character to believe and defend the project in the face of an hypothetical bad deal. This is not a good, trust-generating signal to a loyal community and to possible external future supporters. IMHO, on the contrary, it displays a poor trust in the SNET original project by its own team!\n",
      "\n",
      "I am an old community member, and I respect the teams past work. I also believe in the vision thay lead me to support SNET, and accepting the 2 billion dilution for phase2. Not having finished that and yet asking for the community another faith jump into the void with a sketchy rusjed insuficently informed deal, does not generate trust nor strengthens faith in the project.\n",
      "\n",
      "For all of this I will vote  NO.\n",
      "- User_691575445: Don't be a  poor mind. Why don't you talk also about the advantages...\n",
      "- User_1086637470: Is not me having a poor mind here. I am defending the NO vote. So it is just logical tha lt I explain the arguments against, not the advantages.\n",
      "It is the logical way of debate.\n",
      "If you are pro-deal it should be you stating the advantages, provided you were interested in doing so...\n",
      "\n",
      "- User_1086637470: Why I shall vote NO:\n",
      "\n",
      "1. Rushed vote with WP non-present with enough time before vote to have a healthy debate. Remember: business intelligence tactics include things like this. Quick poorly informed false dicotomies presented as opportunities with time-pressure inciting to FOMO. Classic marketing /sales tactics.\n",
      "2. The feeling that this prssure comes from an urge imposed by FETCH AI plans.\n",
      "3. Badly negotiated deal  to say least.\n",
      "4. Imposing a change of token to holders that modifies previous compromises in SNET ecosystem.\n",
      "5. This token changes will imply i)gas expenditure, ii)tax problems as it is an effective ptlatromonial change, iii) other consequences regarding token utility, staking benefits, airdrops for phase 2 spinoffs and so on. iv) unforeseen consequences.\n",
      "6. Bad image created for a community that either only thinks how fetchai bullrun can benefit ASI token price or that does not believe enough in vision SNET to stay engaged with the course of action AGIX. Or both at the same time. This is a display of project weakness.\n",
      "7. The fact that the SNET team discards the possibility of renegotation of terms after a putative NO victory, display a weak character to believe and defend the project in the face of an hypothetical bad deal. This is not a good, trust-generating signal to a loyal community and to possible external future supporters. IMHO, on the contrary, it displays a poor trust in the SNET original project by its own team!\n",
      "\n",
      "I am an old community member, and I respect the teams past work. I also believe in the vision thay lead me to support SNET, and accepting the 2 billion dilution for phase2. Not having finished that and yet asking for the community another faith jump into the void with a sketchy rusjed insuficently informed deal, does not generate trust nor strengthens faith in the project.\n",
      "\n",
      "For all of this I will vote  NO.\n",
      "- User_691575445: Don't be a  poor mind. Why don't you talk also about the advantages...\n",
      "- User_1363117151: there is a lot of advantages here as well for sure\n",
      "\n",
      "- User_6407863581: Did we not all back the individual projects from a place of faith?\n",
      "\n",
      "- User_478317342: Willing to go against the team will only hurt the project.\n",
      "- User_1086637470: This statement is false, sir.\n",
      "\n",
      "- User_691575445: Maybe people are more interested in they pocket short term view. Than interested in the project itselg\n",
      "\n",
      "- User_5977890525: The worst thing that can happen to a project is a toxic community trying to take control in the name of decentralization.\n",
      "- User_507597398: we have a wonderful community - toxicity has come out of the woodwork this week 🙂\n",
      "- User_5977890525: Your community may be decent, but the government is so ridiculous you wonder how it got there.\n",
      "- User_507597398: i dont really understand this sentence sorry\n",
      "- User_5977890525: Team > Government > Community and the middle part became a bad actor in your case.\n",
      "- User_507597398: ah i think i understand your point - ill leave you to it 🙂\n",
      "\n",
      "- User_418623164: The only somewhat objective alternative would be stopping the release of tokens in each project, which seems impractical.\n",
      "\n",
      "- User_6165637792: It doesn't seem right that they will have to live with the outcome of votes held by 2 other projects, both who will benefit more from the merger\n",
      "\n",
      "- User_2027637001: It should always be okay to take the worst decisions for your community?\n",
      "\n",
      "- User_1639831297: if phase 2 community benefits continue to exist, it hurts less..... but we lose so much sway as a community\n",
      "- User_527061814: I think there is a case to be made for no one entity holding majority.\n",
      "\n",
      "- User_1443579765: You want to water down the value of the project for more ownership\n",
      "\n",
      "- User_5663225598: I like the project\n",
      "\n",
      "- User_2027637001: It just will bring problems\n",
      "Longterm\n",
      "\n",
      "- User_527061814: I also question the idea that they are the ones who least benefit.\n",
      "\n",
      "- User_478317342: Willing to go against the team will only hurt the project.\n",
      "- User_454084975: he's free to raise his concerns tho\n",
      "\n",
      "- User_5375378585: I see more pros than cons. \n",
      "\n",
      "Think of is like this when a company is bigger and are all working towards the same goal they can put resources together streamline projects making it cheaper. Bigger team can share resources and bigger partnerships. \n",
      "The only con I see is the growth might not be as exponential, as the marketcap would be bigger meaning it would be harder to move the price. However a larger marketcap could make it more appealing to bigger investors and bigger partnerships. EG blackrock, nivida\n",
      "Also let’s not forget the ceo of fet was a founding inventor of deepmind who got bought by google\n",
      "\n",
      "- User_5375378585: The only con I see is the growth might not be as big as the marketcap would be bigger meaning it would be harder to move the price. However a larger marketcap could make it more appealing to bigger players (ie blackrock)\n",
      "\n",
      "- User_2002479481: There cant be 100 different crypto projects spreading the talent thin and comptete against the googles of the world\n",
      "user question: What are some negative aspects about this project?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What are some negative aspects about this project?\"\n",
    "response = qa({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some negative aspects about this project include:\n",
      "- Lack of tangible results and financial returns for investors\n",
      "- Concerns about the community potentially ruining the project\n",
      "- Potential for a toxic community trying to take control in the name of decentralization\n",
      "- Uncertainty about the effectiveness of the project and its various side projects\n",
      "- Skepticism about the negotiation process and the overall deal\n",
      "- Disappointment in the lack of adoption and use case across all three projects\n",
      "- Disillusionment with the project's progress and outcomes, leading to doubts about its long-term viability and success\n"
     ]
    }
   ],
   "source": [
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The context given are several messages retrieved from a chat about a blockchain project. Based on those messages try to answer the user question.\n",
      "----------------\n",
      "context: - User_6480686176: How to stake?\n",
      "- User_1723326597: !staking\n",
      "\n",
      "- User_510661770: How to unstake?\n",
      "\n",
      "- User_7131149338: How can I stake my agix\n",
      "\n",
      "- User_1912557943: Hello, I have some questions about staking. Who can assist? :)\n",
      "\n",
      "- User_6989780283: /staking\n",
      "\n",
      "- User_6989780283: /staking\n",
      "\n",
      "- User_378034663: Does anyone know the staking rewards?\n",
      "\n",
      "- User_1518954403: Hey guys, is staking worth it ?\n",
      "\n",
      "- User_327618551: How much fees for staking\n",
      "\n",
      "- User_6281353071: How can i stake agix?\n",
      "- User_1723326597: !staking\n",
      "\n",
      "- User_327618551: /staking\n",
      "\n",
      "- User_6546249709: Where do I stake the token to participate in the launch pad\n",
      "\n",
      "- User_2007302667: !staking\n",
      "\n",
      "- User_6239078091: I need help with my stake token\n",
      "\n",
      "- User_7156382684: What’s the returns like for staking?\n",
      "\n",
      "- User_503303035: !staking\n",
      "\n",
      "- User_503303035: !staking\n",
      "\n",
      "- User_503303035: !staking\n",
      "\n",
      "- User_327618551: Having a staking issue\n",
      "\n",
      "- User_5758419471: may I know the staking website?\n",
      "- User_1723326597: !staking\n",
      "user question: How to do staking?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"How to do staking?\"\n",
    "response = qa({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the chat messages, it seems that the command \"!staking\" is commonly used to inquire about\n",
      "staking in the blockchain project. So, to stake in this project, you can try using the command\n",
      "\"!staking\" or \"/staking\" to get more information or assistance on how to stake your tokens.\n",
      "Additionally, you can also ask for help or clarification from other users who may have experience\n",
      "with staking in the project.\n"
     ]
    }
   ],
   "source": [
    "wrapped_text = textwrap.fill(response[\"result\"], width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The context given are several messages retrieved from a chat about a blockchain project. Based on those messages try to answer the user question.\n",
      "----------------\n",
      "context: - User_7099962622: Any support team here I need help\n",
      "- User_503303035: What do you need?\n",
      "\n",
      "- User_1684147743: Is there a support contact foe staking\n",
      "\n",
      "- User_5684934395: Thank you\n",
      "- User_1723326597: Please use the contact info above and staking support will assist when they are back online on Monday. Include relevant info in your email.\n",
      "\n",
      "- User_6273563012: please, how do i buy?\n",
      "\n",
      "- User_6037030851: I've an issue and need assistance.\n",
      "- User_503303035: Feel free to ask.\n",
      "\n",
      "- User_5830833969: I sent a request via \"contact\" section on the official website, but I didn't receive any response. Is there someone who can assist with official communication?\n",
      "- User_454084975: i can, yes\n",
      "- User_5830833969: Thank you. If it is okay, I will explain its details via dm\n",
      "\n",
      "- User_1592561211: Not sure how you guys reach the admins for support.. my messages tagging them drops out of sight..\n",
      "- User_503303035: What were you after? Feel free to DM if you wish.\n",
      "\n",
      "- User_6692920864: Hello, I need help\n",
      "\n",
      "- User_676760250: Can somebody help me?\n",
      "\n",
      "- User_5838007172: Hi, whom should i contact regarding community parternship proposal?\n",
      "\n",
      "- User_1591880614: is there any real team member support in this chat?\n",
      "\n",
      "- User_1723326597: Sure, how can we help\n",
      "\n",
      "- User_5141274264: What is the best approach to start an account and purchase this in the US?\n",
      "\n",
      "- User_1591880614: I've sent email to the support, hope that's real\n",
      "\n",
      "- User_6273563012: How do I buy\n",
      "\n",
      "- User_818590106: how can i join the project?\n",
      "\n",
      "- User_6303943715: Please guys, any help on this?\n",
      "\n",
      "- User_7156382684: Any admins on to help with an issue?\n",
      "\n",
      "- User_6822359339: How?\n",
      "\n",
      "- User_866729461: hello guys ... Is there any support in Portuguese?\n",
      "user question: How to contact support?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"How to contact support?\"\n",
    "response = qa({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To contact support for the blockchain project, you can use the contact information provided on the\n",
      "official website. Staking support will assist when they are back online on Monday. You can also\n",
      "reach out to team members directly via direct message (DM) on the chat platform. Additionally, you\n",
      "can send an email to the support team for assistance.\n"
     ]
    }
   ],
   "source": [
    "wrapped_text = textwrap.fill(response[\"result\"], width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The context given are several messages retrieved from a chat about a blockchain project. Based on those messages try to answer the user question.\n",
      "----------------\n",
      "context: - User_7086847052: Does anyone look for a developer?\n",
      "\n",
      "- User_7163446993: Is there anyone looking for a developer?\n",
      "\n",
      "- User_7026075085: plz let me know if anyone looking for a dev\n",
      "\n",
      "- User_454084975: Our website has more info\n",
      "\n",
      "- User_6974589243: Does anyone need a developer?\n",
      "- User_1723326597: !jobs\n",
      "\n",
      "- User_6974589243: Does anyone look for a developer?\n",
      "- User_1723326597: No, thanks\n",
      "\n",
      "- User_1278149190: Does anyone need a d eveloper?\n",
      "- User_1723326597: !jobs\n",
      "\n",
      "- User_6537699716: Does anyone need D2veloper?\n",
      "\n",
      "- User_527061814: For me a single token is a prerequisite to offering developers (external) a joined up workflow. The more they can do to integrate that user experience the better.\n",
      "\n",
      "- User_411905789: Are you guys doing the dev work or are they? Who are the ones who needs these things?\n",
      "\n",
      "- User_454084975: theres a lot of info out there ;)\n",
      "\n",
      "- User_7178221876: Hello Everyone \n",
      "As a web & blockchain developer, I am looking for a apportunity. \n",
      "If you have an idea or project, please DM me\n",
      "- User_1723326597: !jobs\n",
      "\n",
      "- User_5469269968: How come website had not been updated and Twitter is not active ?\n",
      "- User_481359444: These will be developed\n",
      "\n",
      "- User_5199929701: I want to get involved in de-projects as a dev with my experienced skills. Please let me know if you have any open positions.\n",
      "\n",
      "- User_454084975: that has a lot of info on it\n",
      "\n",
      "- User_454084975: Develop an ai service and put it on our platform\n",
      "\n",
      "- User_1363117151: daily tasks helping there is so many stuff we can developed endless opportunity\n",
      "\n",
      "- User_6245108578: I'm seasoned developer with extensive experience in full-stack and blockchain technologies. I am actively seeking new opportunities to leverage my skills in web3 app development such as EVM, Solana and XRPL.\n",
      "\n",
      "- User_6557405475: Pretty simple, just follow the projects on x. They have posted all the info\n",
      "\n",
      "- User_454084975: I'm not a dev ;)\n",
      "user question: Information for developers\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"Information for developers\"\n",
    "response = qa({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the messages in the chat, it seems like there are developers actively looking for\n",
      "opportunities and projects to work on. Some users have mentioned their experience and skills in web\n",
      "development, blockchain technologies, and AI services. Additionally, there are references to\n",
      "websites with more information about projects and opportunities for developers. If you are a\n",
      "developer looking for information or opportunities, you may want to reach out to some of the users\n",
      "in the chat who have expressed interest in working on projects or check out the websites mentioned\n",
      "for more information.\n"
     ]
    }
   ],
   "source": [
    "wrapped_text = textwrap.fill(response[\"result\"], width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Both semantic search and retrieval augmented generation output qualitty depend directly on the quality of the source data. In this case, telegram channels do not always seem to provide relevant information about a project but might be suited for specific user queries such as finding answers of a specific technical question. But for generaly queries about the project uses cases, this data sources is not suitable. Other data sources should be explored for better quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telegram-nlp-6m6KizWy-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
