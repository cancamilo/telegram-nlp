{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Demo with telegram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "from langchain.llms import OpenAIChat\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using existing Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index initialization\n",
    "from semantic_search_generator import SemanticSearchGenerator\n",
    "\n",
    "channel_id = \"@runonflux\"\n",
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "INDEX_NAME = \"telegram-embeddings\"\n",
    "\n",
    "generator = SemanticSearchGenerator(model_name)\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=os.environ[\"PINECONE_APIKEY\"],\n",
    "    environment=\"us-west1-gcp\"\n",
    ")\n",
    "\n",
    "# connect to index\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt_template = \"\"\"Use the chat messages (not sorted in any particular order) below to answer the given user query:\n",
    "    messages_list: {messages}\n",
    "    query: {query}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"messages\", \"query\"])\n",
    "llm = OpenAIChat(temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_results(query, limit=50):\n",
    "    query_emb = generator.encode_messages(query)\n",
    "\n",
    "    results = index.query(\n",
    "      vector=query_emb.tolist(),\n",
    "      top_k=limit,\n",
    "      include_values=False,\n",
    "      include_metadata=True\n",
    "    )\n",
    "\n",
    "    messages = []\n",
    "    for item in results[\"matches\"]:\n",
    "        # print(f\"\\nscore {item['score']}\")\n",
    "        # print(item[\"metadata\"][\"clean_message\"])\n",
    "        messages.append(item[\"metadata\"][\"clean_message\"])\n",
    "\n",
    "    return messages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is good about this project?\"\n",
    "messages = search_results(query)\n",
    "inputs = [{\"message\": msg} for _, msg in zip(range(len(messages)), messages)]\n",
    "result = chain.run({\"messages\":inputs, \"query\":query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what do users complain about this project?\"\n",
    "messages = search_results(query)\n",
    "inputs = [{\"index\": i, \"message\": msg} for i, msg in zip(range(len(messages)), messages)]\n",
    "result = chain.run({\"messages\":inputs, \"query\":query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# load telegram messages\n",
    "channel_id = \"@runonflux\"\n",
    "df = pd.read_csv(f\"notebooks/data/{channel_id}.csv\")\n",
    "\n",
    "df_loader = DataFrameLoader(df, page_content_column=\"clean_message\")\n",
    "docs = df_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# comput embeddings and load to chroma\n",
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to query\n",
    "def search_db(db_client, query: str, top_k = 100):\n",
    "    query = \"use cases\"\n",
    "    docs = db_client.similarity_search(query, k=top_k)\n",
    "\n",
    "    # print results\n",
    "    for item in docs[:10]:\n",
    "        print(f\"- {item.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peristent Chroma client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to delete  Collection embeddings_collection_runonflux does not exist.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "\n",
    "CLEAR_COLLECTION= True\n",
    "\n",
    "if CLEAR_COLLECTION:\n",
    "    try:\n",
    "        persistent_client.delete_collection(f\"embeddings_collection_{channel_id[1:]}\")\n",
    "    except Exception as e:\n",
    "        print(\"unable to delete \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "client = Chroma.from_documents(\n",
    "    docs, \n",
    "    embedding_function, \n",
    "    client=persistent_client, \n",
    "    collection_name = f\"embeddings_collection_{channel_id[1:]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Okay, so where do you run into problems?\n",
      "- Can you please write in simple words the usecases of flux coin ? Services which requires flux token ?\n",
      "- Harness the power of decentralisation Explore RunOnFlux use cases Let's read onhttpstwitter.comHouseofChimerastatus1709901477689364513\n",
      "- in addition to securing the network you also provide a real world case for solving problems  eg genome sequencing, graphics rendering, etc...\n",
      "- Dont use discord. Whats the drama? Fill us in\n",
      "- plz let me know if you are in need of my skills.\n",
      "- What are the $FLUX usecases?Let's find out httpstwitter.comHouseofChimerastatus1671902756808818690\n",
      "- Do you have any learning materials in this area? I don't quite understand how to operate it specifically.\n",
      "- What we need is one major user to take excess capacity\n",
      "- proof of concept is like the first iteration  will it work the way its planned  are there any changes needed  testing the concept is good\n"
     ]
    }
   ],
   "source": [
    "query = \"use cases\"\n",
    "search_db(client, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = \"@runonflux\"\n",
    "df = pd.read_csv(f\"notebooks/data/{channel_id}.csv\")\n",
    "df_loader = DataFrameLoader(df, page_content_column=\"clean_message\")\n",
    "docs = df_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to delete  Collection openai_embeddings_runonflux does not exist.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "\n",
    "CLEAR_COLLECTION= True\n",
    "\n",
    "if CLEAR_COLLECTION:\n",
    "    try:\n",
    "        persistent_client.delete_collection(f\"openai_embeddings_{channel_id[1:]}\")\n",
    "    except Exception as e:\n",
    "        print(\"unable to delete \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_function = OpenAIEmbeddings()\n",
    "\n",
    "client = Chroma.from_documents(\n",
    "    docs, \n",
    "    embedding_function, \n",
    "    client=persistent_client, \n",
    "    collection_name = f\"openai_embeddings_{channel_id[1:]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Okay, so where do you run into problems?\n",
      "- Can you please write in simple words the usecases of flux coin ? Services which requires flux token ?\n",
      "- Harness the power of decentralisation Explore RunOnFlux use cases Let's read onhttpstwitter.comHouseofChimerastatus1709901477689364513\n",
      "- in addition to securing the network you also provide a real world case for solving problems  eg genome sequencing, graphics rendering, etc...\n",
      "- should i just use this instead then ?\n",
      "- Dont use discord. Whats the drama? Fill us in\n",
      "- plz let me know if you are in need of my skills.\n",
      "- What are the $FLUX usecases?Let's find out httpstwitter.comHouseofChimerastatus1671902756808818690\n",
      "- Do you have any learning materials in this area? I don't quite understand how to operate it specifically.\n",
      "- What we need is one major user to take excess capacity\n"
     ]
    }
   ],
   "source": [
    "query = \"use cases\"\n",
    "search_db(client, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(), chain_type=\"stuff\", retriever=client.as_retriever(search_type=\"mmr\", search_kwargs={'fetch_k': 30}), return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are some use cases of flux?\"\n",
    "response = qa({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some potential use cases of Flux include:\\n\\n1. Decentralized Finance (DeFi): Flux can be used for various DeFi applications such as lending, borrowing, and decentralized exchanges.\\n\\n2. Gaming: Flux can enable in-game economies, item ownership, and trading of virtual assets.\\n\\n3. Supply Chain Management: Flux can be utilized to track and verify the provenance of goods, ensuring transparency and efficiency in supply chain operations.\\n\\n4. Content Monetization: Flux can provide a platform for creators to monetize their digital content, such as music, videos, and art, through decentralized marketplaces.\\n\\n5. Decentralized Governance: Flux can facilitate decentralized decision-making processes, allowing token holders to participate in governance and voting.\\n\\nThese are just some potential use cases, and the actual applications of Flux may expand as the ecosystem evolves.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telegram-nlp-6m6KizWy-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
