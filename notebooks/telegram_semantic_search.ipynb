{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search on telegram channels\n",
    "\n",
    "Showcasing how to extract telegram messages for a specific channel and perform semantic search given an user query. \n",
    "I use pretrained models for semantic search from huggingface.\n",
    "\n",
    "The fetched messages are first embbeded with the model and then uploaded to a pinecode index. Then the query is embedded and compared against the indexed data.\n",
    "\n",
    "An option for future work is to fine tune a model specific for telegram messages of certain topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "from telethon.sync import TelegramClient\n",
    "from IPython.display import display\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "import pinecone\n",
    "\n",
    "from telethon.tl.types import InputMessagesFilterEmpty\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# do not truncate column width in pandas\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_id = os.environ[\"TELEGRAM_API_ID\"]\n",
    "api_hash = os.environ[\"TELEGRAM_API_HASH\"]\n",
    "pinecone_key = os.environ[\"PINECONE_APIKEY\"]\n",
    "phone = os.environ[\"TELEGRAM_PHONE\"]\n",
    "username = os.environ[\"TELEGRAM_USERNAME\"]\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fetching and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = []\n",
    "\n",
    "columns = [\"channel_name\", \"id\", \"peer_id\", \"date\", \"message\", \"out\", \"mentioned\",\n",
    "        \"media_unread\", \"silent\", \"post\", \"from_scheduled\", \"legacy\", \n",
    "        \"edit_hide\", \"pinned\",\"noforwards\", \"from_id\", \"fwd_from\", \"via_bot_id\",\n",
    "        \"reply_to\", \"media\", \"reply_markup\", \"entities\", \"views\",\n",
    "        \"forwards\", \"replies\", \"edit_date\", \"post_author\", \"grouped_id\",\n",
    "        \"reactions\", \"restriction_reason\", \"ttl_period\"]\n",
    "\n",
    "client = TelegramClient(f\"../sessions_data/{phone}\", api_id, api_hash)\n",
    "channel_id = \"singularitynet\"\n",
    "n = 1000\n",
    "\n",
    "async with client:        \n",
    "    async for msg in client.iter_messages(channel_id, filter=InputMessagesFilterEmpty, limit=n):\n",
    "        try:\n",
    "            pd_data.append((channel_id, msg.id, msg.peer_id, msg.date, msg.message,\n",
    "                    msg.out, msg.mentioned, msg.media_unread, msg.silent,msg.post,\n",
    "                    msg.from_scheduled, msg.legacy, msg.edit_hide, msg.pinned, msg.noforwards,\n",
    "                    msg.from_id.user_id if hasattr(msg.from_id, \"user_id\") else msg.from_id.channel_id, msg.fwd_from, msg.via_bot_id, msg.reply_to, msg.media, msg.reply_markup,\n",
    "                    msg.entities, msg.views, msg.forwards, msg.replies, msg.edit_date, msg.post_author,\n",
    "                    msg.grouped_id, msg.reactions, msg.restriction_reason, msg.ttl_period\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(msg.from_id)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>peer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>out</th>\n",
       "      <th>mentioned</th>\n",
       "      <th>media_unread</th>\n",
       "      <th>silent</th>\n",
       "      <th>post</th>\n",
       "      <th>from_scheduled</th>\n",
       "      <th>legacy</th>\n",
       "      <th>edit_hide</th>\n",
       "      <th>pinned</th>\n",
       "      <th>noforwards</th>\n",
       "      <th>from_id</th>\n",
       "      <th>fwd_from</th>\n",
       "      <th>via_bot_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>media</th>\n",
       "      <th>reply_markup</th>\n",
       "      <th>entities</th>\n",
       "      <th>views</th>\n",
       "      <th>forwards</th>\n",
       "      <th>replies</th>\n",
       "      <th>edit_date</th>\n",
       "      <th>post_author</th>\n",
       "      <th>grouped_id</th>\n",
       "      <th>reactions</th>\n",
       "      <th>restriction_reason</th>\n",
       "      <th>ttl_period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_name</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">singularitynet</th>\n",
       "      <th>1007866</th>\n",
       "      <td>PeerChannel(channel_id=1140090881)</td>\n",
       "      <td>2024-04-28 19:47:12+00:00</td>\n",
       "      <td>‚ö†Ô∏è Safety Warning ‚ÄºÔ∏è \\n\\n‚ÄºÔ∏è The ASI token is not available for sale, trading, airdrop, etc. \\n\\nüî∫ There is no ASI contract (yet). \\n\\nüîπ Stay informed by reading pinned messages and announcements i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>210944655</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[MessageEntityBold(offset=3, length=14), MessageEntityBold(offset=30, length=3), MessageEntityBold(offset=40, length=6), MessageEntityUnderline(offset=95, length=23)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReplies(replies=0, replies_pts=1422986, comments=False, recent_repliers=[], channel_id=None, max_id=None, read_max_id=None)</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007864</th>\n",
       "      <td>PeerChannel(channel_id=1140090881)</td>\n",
       "      <td>2024-04-28 19:35:07+00:00</td>\n",
       "      <td>they have a $2.5 million marketcap.  I would just be carefull and check contract addressü§∑‚Äç‚ôÇÔ∏è</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>578573938</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MessageReplyHeader(reply_to_scheduled=False, forum_topic=False, quote=False, reply_to_msg_id=1007855, reply_to_peer_id=None, reply_from=None, reply_media=None, reply_to_top_id=None, quote_text=Non...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   peer_id  \\\n",
       "channel_name   id                                            \n",
       "singularitynet 1007866  PeerChannel(channel_id=1140090881)   \n",
       "               1007864  PeerChannel(channel_id=1140090881)   \n",
       "\n",
       "                                            date  \\\n",
       "channel_name   id                                  \n",
       "singularitynet 1007866 2024-04-28 19:47:12+00:00   \n",
       "               1007864 2024-04-28 19:35:07+00:00   \n",
       "\n",
       "                                                                                                                                                                                                                        message  \\\n",
       "channel_name   id                                                                                                                                                                                                                 \n",
       "singularitynet 1007866  ‚ö†Ô∏è Safety Warning ‚ÄºÔ∏è \\n\\n‚ÄºÔ∏è The ASI token is not available for sale, trading, airdrop, etc. \\n\\nüî∫ There is no ASI contract (yet). \\n\\nüîπ Stay informed by reading pinned messages and announcements i...   \n",
       "               1007864                                                                                                             they have a $2.5 million marketcap.  I would just be carefull and check contract addressü§∑‚Äç‚ôÇÔ∏è   \n",
       "\n",
       "                          out  mentioned  media_unread  silent   post  \\\n",
       "channel_name   id                                                       \n",
       "singularitynet 1007866  False      False         False   False  False   \n",
       "               1007864  False      False         False   False  False   \n",
       "\n",
       "                       from_scheduled  legacy edit_hide pinned noforwards  \\\n",
       "channel_name   id                                                           \n",
       "singularitynet 1007866          False   False     False  False      False   \n",
       "               1007864          False   False     False  False      False   \n",
       "\n",
       "                          from_id fwd_from via_bot_id  \\\n",
       "channel_name   id                                       \n",
       "singularitynet 1007866  210944655     None       None   \n",
       "               1007864  578573938     None       None   \n",
       "\n",
       "                                                                                                                                                                                                                       reply_to  \\\n",
       "channel_name   id                                                                                                                                                                                                                 \n",
       "singularitynet 1007866                                                                                                                                                                                                     None   \n",
       "               1007864  MessageReplyHeader(reply_to_scheduled=False, forum_topic=False, quote=False, reply_to_msg_id=1007855, reply_to_peer_id=None, reply_from=None, reply_media=None, reply_to_top_id=None, quote_text=Non...   \n",
       "\n",
       "                       media reply_markup  \\\n",
       "channel_name   id                           \n",
       "singularitynet 1007866  None         None   \n",
       "               1007864  None         None   \n",
       "\n",
       "                                                                                                                                                                                      entities  \\\n",
       "channel_name   id                                                                                                                                                                                \n",
       "singularitynet 1007866  [MessageEntityBold(offset=3, length=14), MessageEntityBold(offset=30, length=3), MessageEntityBold(offset=40, length=6), MessageEntityUnderline(offset=95, length=23)]   \n",
       "               1007864                                                                                                                                                                    None   \n",
       "\n",
       "                        views  forwards  \\\n",
       "channel_name   id                         \n",
       "singularitynet 1007866    NaN       NaN   \n",
       "               1007864    NaN       NaN   \n",
       "\n",
       "                                                                                                                                                   replies  \\\n",
       "channel_name   id                                                                                                                                            \n",
       "singularitynet 1007866  MessageReplies(replies=0, replies_pts=1422986, comments=False, recent_repliers=[], channel_id=None, max_id=None, read_max_id=None)   \n",
       "               1007864                                                                                                                                None   \n",
       "\n",
       "                       edit_date post_author  grouped_id reactions  \\\n",
       "channel_name   id                                                    \n",
       "singularitynet 1007866       NaT        None         NaN      None   \n",
       "               1007864       NaT        None         NaN      None   \n",
       "\n",
       "                       restriction_reason ttl_period  \n",
       "channel_name   id                                     \n",
       "singularitynet 1007866               None       None  \n",
       "               1007864               None       None  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pd_data, columns=columns)\n",
    "df = df[df['message'] != ''] # remove empty messages\n",
    "df = df[~df[\"message\"].isna()] # remove nan text\n",
    "df = df.set_index([\"channel_name\", \"id\"])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "def extract_reply_id(val):\n",
    "    \"\"\" search for the matching id\n",
    "    \"\"\"\n",
    "    if isinstance(val, str):\n",
    "        match = re.search(r'reply_to_msg_id=(\\d+)', val)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def compute_message_historical(df):\n",
    "    # compute message history for each message if available\n",
    "\n",
    "    df_extended = df.copy()\n",
    "    df_extended[\"in_history\"] = False\n",
    "    df_extended[\"reply_to_msg_id\"] = df_extended[\"reply_to\"].apply(lambda x: int(x.reply_to_msg_id) if x is not None else None)\n",
    "\n",
    "    # Only use if Class was parsed from text\n",
    "    # df['reply_to_msg_id'] = df['reply_to'].apply(extract_reply_id)\n",
    "    \n",
    "    for (channel_name, message_id), row in df_extended.iterrows():\n",
    "        history = [f\"User_{row['from_id']}: {row['message']}\"] # Initialize historical with current message\n",
    "        reply_id = row[\"reply_to_msg_id\"]\n",
    "        \n",
    "        try:\n",
    "            while not np.isnan(reply_id) and (channel_name, reply_id) in df_extended.index:\n",
    "\n",
    "                df_extended.loc[(channel_name, reply_id), \"in_history\"] = True\n",
    "\n",
    "                # Get reply row\n",
    "                reply_row = df_extended.loc[(channel_name, reply_id)]\n",
    "\n",
    "                # Update history\n",
    "                history.append(f\"User_{reply_row['from_id']}: {reply_row['message']}\")\n",
    "\n",
    "                # Delete message appended to history\n",
    "                df_extended = df_extended.drop((channel_name, reply_id))                \n",
    "\n",
    "                # assign next reply id\n",
    "                reply_id = reply_row[\"reply_to_msg_id\"]\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(type(reply_id))\n",
    "            print(\"something failed\", e)\n",
    "\n",
    "        df_extended.loc[(channel_name, message_id), \"history\"] = str(history[::-1])\n",
    "\n",
    "        # Ignore already iterated replies\n",
    "\n",
    "    df_extended[\"history\"] = df_extended[\"history\"].apply(ast.literal_eval)\n",
    "    df_extended[\"history_str\"] = df_extended[\"history\"].apply(lambda x: \"- \" + \"\\n- \".join(x))\n",
    "    df_extended[\"thread_length\"] = df_extended[\"history\"].str.len()\n",
    "    return df_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus = compute_message_historical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- User_630927899.0: We need to migrate?\n",
      "- User_1723326597.0: Yes, for non-custodial wallets, there will be a migration tool\n",
      "- User_630927899.0: Ok when how\n",
      "- User_1723326597.0: Here is approximate timeline\n",
      "- User_630927899.0: Ok thanks maybe make a warning about scammers to. I've got like 6 dm from \"admin\" here trying to \"help\" me migrate\n",
      "- User_1723326597: We always include a warning, see last sentence in the post above yours. Please stay safe and block/report scammers messaging you ü§ù\n"
     ]
    }
   ],
   "source": [
    "print(df_plus[df_plus['history'].apply(lambda x: len(x) > 1)].iloc[11][\"history_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total message count 972\n",
      "token count distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10     0.0\n",
       "0.25     0.0\n",
       "0.50     2.0\n",
       "0.75    10.0\n",
       "0.95    54.0\n",
       "0.98    54.0\n",
       "Name: token_count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data cleaning and filtering \n",
    "\n",
    "df_plus[\"token_count\"] = df_plus[\"message\"].apply(lambda x: len(x.split(\" \"))  if type(x) == str else 0)\n",
    "print(\"Total message count\", len(df_plus))\n",
    "\n",
    "# What is the distribution of token counts?\n",
    "print(\"token count distribution\")\n",
    "display(df_plus[\"token_count\"].quantile([.1, .25, .5, .75, .95, 0.98]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'singularitynet'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus.to_csv(f\"data/{channel_id}_replies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from semantic_search_generator import SemanticSearchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'notebooks/data/@runonflux_replies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m channel_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@runonflux\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnotebooks/data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchannel_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_replies.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m messages \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_message\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m      4\u001b[0m messages\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/telegram-nlp-cUHCjj8z-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/telegram-nlp-cUHCjj8z-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/telegram-nlp-cUHCjj8z-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/telegram-nlp-cUHCjj8z-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/telegram-nlp-cUHCjj8z-py3.10/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'notebooks/data/@runonflux_replies.csv'"
     ]
    }
   ],
   "source": [
    "channel_id = \"@runonflux\"\n",
    "df = pd.read_csv(f\"notebooks/data/{channel_id}_replies.csv\")\n",
    "messages = df.sample(10, random_state=11)[\"clean_message\"].to_list()\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2212686538696289 My buy in was 60c but I asked literally everyone big in the flux space if we could maintain the dollar and they were all bullish including Dan. I wanted to sell to buy back cheaper and am kicking myself I didn't lol\n",
      "0.10311347246170044 For example, my stratus gives me 110 a month with current price and APR. Cost of the dedicated server is 70.If i wanted to run cumulus instead, it would be 40 cumulus, giving me about 220 total a month, but costing me about 210 in VPS cost.Plus now i have to monitor and maintain 40 nodes instead of one \n",
      "0.09914617985486984 Join our CBO Davy Wittock for a special mining episode for Around the Blockchain today at 5 PM EST Get ready for an exciting discussion about Proof of Useful Work and the future of mining Link  httpsyoutube.comaroundtheblockchainofficial\n",
      "0.08931327611207962 I would suggest you to stop promoting the group BettyK0\n",
      "0.06712281703948975 Anybody withdraw Flux  from CoinEX?Looks suspended\n",
      "0.04982435703277588  many crypto projects are one sided in their community. Most are in discord, some are almost exclusively on telegram, some loosely on Twitter....\n",
      "0.04696136713027954 Yes deleting nodes because of low rewards is the most scary thing  we may even see less than 0.20 \n",
      "-0.005718698725104332 We only have 400mil flux  was it an amount allocated for this parallel claims ?\n",
      "-0.024313876405358315 What's command on TG Flux  to check amount stake titan node ?\n",
      "-0.048260483890771866 This flux 4 upgrade made 6 of my nodes go offline.  Now is dos mode.How to get out if this please?\n"
     ]
    }
   ],
   "source": [
    "generator = SemanticSearchGenerator()\n",
    "\n",
    "# Text to encode\n",
    "query = \"investment strategy\"\n",
    "doc_score_pairs = generator.search_batch(query, messages, device=\"mps\")\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs[:10]:\n",
    "    print(score, doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = \"@runonflux\"\n",
    "model_name = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "df = pd.read_csv(f\"notebooks/data/{channel_id}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=os.environ[\"PINECONE_APIKEY\"],\n",
    "    environment=\"us-west1-gcp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings model\n",
    "multi_qa_encoder = SentenceTransformer(model_name)\n",
    "\n",
    "query = \"This coin will moon soon\"\n",
    "vec = multi_qa_encoder.encode(query, convert_to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_DELETE_INDEX = False # Set True only for initializing the index\n",
    "INDEX_NAME = \"telegram-embeddings\"\n",
    "\n",
    "if FORCE_DELETE_INDEX:\n",
    "    pinecone.delete_index(INDEX_NAME)\n",
    "\n",
    "if INDEX_NAME not in pinecone.list_indexes():\n",
    "    pinecone.create_index(INDEX_NAME, dimension=len(vec))\n",
    "    \n",
    "# connect to index\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    has_gpu = torch.cuda.is_available()\n",
    "    has_mps = torch.backends.mps.is_built()\n",
    "    device = \"mps\" if has_mps else \"gpu\" if has_gpu else \"cpu\"\n",
    "    return device\n",
    "\n",
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to index\n",
    "COMPUTE_EMBEDDINGS = True\n",
    "if COMPUTE_EMBEDDINGS:\n",
    "    # create embeddings\n",
    "    df[\"embeddings_cpu\"] = df[\"clean_message\"].apply(lambda x: multi_qa_encoder.encode(x, device=\"cpu\", convert_to_tensor=True, show_progress_bar=False))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SemanticSearchGenerator(model_name)\n",
    "\n",
    "# Faster with mps\n",
    "df[\"embeddings_mps\"] = df[\"clean_message\"].apply(lambda x: generator.encode_messages(x, device=\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings_cpu</th>\n",
       "      <th>embeddings_mps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tensor(-0.0749), tensor(-0.1107), tensor(-0.0339), tensor(0.0374), tensor(-0.0197), tensor(0.0569), tensor(0.0786), tensor(-0.0522), tensor(-0.0159), tensor(0.0207), tensor(-0.0155), tensor(-0.01...</td>\n",
       "      <td>[[tensor(-0.0749, device='mps:0'), tensor(-0.1107, device='mps:0'), tensor(-0.0339, device='mps:0'), tensor(0.0374, device='mps:0'), tensor(-0.0197, device='mps:0'), tensor(0.0569, device='mps:0')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tensor(0.0309), tensor(-0.0022), tensor(0.0416), tensor(0.0120), tensor(0.0061), tensor(0.0405), tensor(-0.1566), tensor(-0.0018), tensor(-0.1030), tensor(0.0587), tensor(0.0292), tensor(0.0281),...</td>\n",
       "      <td>[[tensor(0.0309, device='mps:0'), tensor(-0.0022, device='mps:0'), tensor(0.0416, device='mps:0'), tensor(0.0120, device='mps:0'), tensor(0.0061, device='mps:0'), tensor(0.0405, device='mps:0'), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tensor(0.0337), tensor(-0.0346), tensor(-0.0315), tensor(-0.0759), tensor(-0.0189), tensor(0.0352), tensor(-0.0644), tensor(0.0090), tensor(-0.0890), tensor(-0.0099), tensor(-0.1018), tensor(-0.0...</td>\n",
       "      <td>[[tensor(0.0337, device='mps:0'), tensor(-0.0346, device='mps:0'), tensor(-0.0315, device='mps:0'), tensor(-0.0759, device='mps:0'), tensor(-0.0189, device='mps:0'), tensor(0.0352, device='mps:0')...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                            embeddings_cpu  \\\n",
       "0  [tensor(-0.0749), tensor(-0.1107), tensor(-0.0339), tensor(0.0374), tensor(-0.0197), tensor(0.0569), tensor(0.0786), tensor(-0.0522), tensor(-0.0159), tensor(0.0207), tensor(-0.0155), tensor(-0.01...   \n",
       "1  [tensor(0.0309), tensor(-0.0022), tensor(0.0416), tensor(0.0120), tensor(0.0061), tensor(0.0405), tensor(-0.1566), tensor(-0.0018), tensor(-0.1030), tensor(0.0587), tensor(0.0292), tensor(0.0281),...   \n",
       "2  [tensor(0.0337), tensor(-0.0346), tensor(-0.0315), tensor(-0.0759), tensor(-0.0189), tensor(0.0352), tensor(-0.0644), tensor(0.0090), tensor(-0.0890), tensor(-0.0099), tensor(-0.1018), tensor(-0.0...   \n",
       "\n",
       "                                                                                                                                                                                            embeddings_mps  \n",
       "0  [[tensor(-0.0749, device='mps:0'), tensor(-0.1107, device='mps:0'), tensor(-0.0339, device='mps:0'), tensor(0.0374, device='mps:0'), tensor(-0.0197, device='mps:0'), tensor(0.0569, device='mps:0')...  \n",
       "1  [[tensor(0.0309, device='mps:0'), tensor(-0.0022, device='mps:0'), tensor(0.0416, device='mps:0'), tensor(0.0120, device='mps:0'), tensor(0.0061, device='mps:0'), tensor(0.0405, device='mps:0'), t...  \n",
       "2  [[tensor(0.0337, device='mps:0'), tensor(-0.0346, device='mps:0'), tensor(-0.0315, device='mps:0'), tensor(-0.0759, device='mps:0'), tensor(-0.0189, device='mps:0'), tensor(0.0352, device='mps:0')...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"embeddings_cpu\", \"embeddings_mps\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "UPLOAD_VECTORS = False # only for index initialization\n",
    "if UPLOAD_VECTORS:    \n",
    "    batch_size = 1000\n",
    "    total_batches = math.ceil(len(df) / batch_size)\n",
    "    start = 0\n",
    "\n",
    "    for i in range(total_batches):\n",
    "        index_upsert = [] # always initialize for each batch        \n",
    "        end = start + batch_size\n",
    "\n",
    "        print(f\"iterating messages {start}-{end}\")\n",
    "        for j, item in df[start:end].iterrows():\n",
    "            index_upsert += [\n",
    "                    (str(j), \n",
    "                    item[\"embeddings_cpu\"].tolist(),\n",
    "                    {\n",
    "                        \"clean_message\": item[\"clean_message\"],\n",
    "                        \"channel_name\": item[\"channel_name\"],\n",
    "                        \"messagee_id\": item[\"id\"]\n",
    "                    })\n",
    "            ]\n",
    "        start = end\n",
    "        print(f\"inserting batch {i}\")\n",
    "        index.upsert(vectors=index_upsert) # can contain maximum 1000 items        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_results(query, limit=20):\n",
    "    query_emb = generator.encode_messages(query)\n",
    "\n",
    "    results = index.query(\n",
    "      vector=query_emb.tolist(),\n",
    "      top_k=limit,\n",
    "      include_values=False,\n",
    "      include_metadata=True\n",
    "    )\n",
    "\n",
    "    messages = []\n",
    "    for item in results[\"matches\"]:\n",
    "        print(f\"\\nscore {item['score']}\")\n",
    "        print(item[\"metadata\"][\"clean_message\"])\n",
    "        messages.append(item[\"metadata\"][\"clean_message\"])\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.410763919\n",
      "Typical bear market... Engagement drops, people hesitate. Meanwhile the team continues to build, POUW just presented a couple of weeks ago\n",
      "\n",
      "score 0.401366264\n",
      "keep an eye on announcements\n",
      "\n",
      "score 0.387041956\n",
      "Nothing happened, bear markets are a bitch\n",
      "\n",
      "score 0.362539232\n",
      "If you interested list in our exchange I can help you\n",
      "\n",
      "score 0.350785732\n",
      "Bearmarkets dont last forever. Unless you are in a scam project. I dont see any other thing here than non stopping hardwork. So chill \n"
     ]
    }
   ],
   "source": [
    "query = \"bearish outlook\"\n",
    "search_results(query, limit=5);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.501404643\n",
      "Hey here A beautiful week to all, its amazing how when the market is bearing or in halt the vibes in communities change, you can see clearly the vision and the rational unlike in bull where everyone is jumping in without research\n",
      "\n",
      "score 0.4879556\n",
      "I've never been a fan of the bullish halving narrative, to many disappointed people who fell for the hype.\n",
      "\n",
      "score 0.407264948\n",
      "Who said anything about expecting a bull run ? I said i will cash out my flux when it hits 1$ again\n",
      "\n",
      "score 0.40503487\n",
      "Is there a bot's news function or roadmap?\n",
      "\n",
      "score 0.404052913\n",
      "I know what you mean but in bull it will be worthed\n",
      "\n",
      "score 0.403915346\n",
      "Of course but hopefully not until next bull run to maximise exposure\n",
      "\n",
      "score 0.400119781\n",
      " We're excited to introduce a new speaker, Daniel Weiss httpswww.linkedin.comindanielweissesqcpaHe will join a panel discussion on the topic \"The Heart of AI Governance, Data, and Society's Wellbeing\".Join us in Florida for our exciting Web3 event. Get your tickets now at httpscypherpunk2023.com\n",
      "\n",
      "score 0.3980802\n",
      "Great news  Should keep the circulating supply smaller now . Now only mining can increase it\n",
      "\n",
      "score 0.397279531\n",
      "Nothing happened, bear markets are a bitch\n",
      "\n",
      "score 0.38933146\n",
      "I am guessing the hostnodes people are even more upset now \n",
      "\n",
      "score 0.388903707\n",
      "keep an eye on announcements\n",
      "\n",
      "score 0.381805092\n",
      "Could thek team make some announcements show ambitions and push the real thing\n",
      "\n",
      "score 0.378582537\n",
      "So hyped for this event\n",
      "\n",
      "score 0.376104176\n",
      " Thrilled to announce new cypherpunk2023 speaker, Samuel Armes, delving into \"The Politics of CBDCs.\"Don't miss out on this exciting Web3 conference, happening on Sep. 2728 in Florida Secure your ticket at httpscypherpunk2023.com.\n",
      "\n",
      "score 0.375007361\n",
      "soon  wait for announcement\n",
      "\n",
      "score 0.371853083\n",
      "Someone pumped it before the official announcement\n",
      "\n",
      "score 0.362896532\n",
      "$10 in bull is almost guaranteed given the product and revenue growth imho. Short term I am concerned for node losses if we go much lower .10 as you mention would be very bad for node retention.\n",
      "\n",
      "score 0.362876\n",
      " releasing an article about it soon\n",
      "\n",
      "score 0.362059325\n",
      "no announcement yet  should be within a few hours i guess...\n",
      "\n",
      "score 0.353994638\n",
      " Exciting news FLUX is now listed on the US exchange UpholdInc.This move not only solidifies our commitment to regulatory compliance but also broadens the horizons for our USbased community members.Expanding secure trading options. Stay tuned for updates and happy trading httpsuphold.com\n"
     ]
    }
   ],
   "source": [
    "query = \"bullish news\"\n",
    "search_results(query);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.790179\n",
      "there is no pouw yet  whats the question?\n",
      "\n",
      "score 0.697877347\n",
      "Pouw isn't even live yet.Also there's still a lot of hardware available i think the network is at 40% right now\n",
      "\n",
      "score 0.691974163\n",
      "Hi guys what is the latest re. POuW?\n",
      "\n",
      "score 0.682593167\n",
      "Hi , you can discuss PoUW in the mining section. All news will be in the announcements section.\n",
      "\n",
      "score 0.659035504\n",
      "Not atm.. Pouw coming towards end of the year\n"
     ]
    }
   ],
   "source": [
    "query = \"PouW\"\n",
    "search_results(query, limit=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.661882877\n",
      "make some node will be fine\n",
      "\n",
      "score 0.655703783\n",
      "If you create the node as privileged it should be good from the start\n",
      "\n",
      "score 0.6469993\n",
      "All nodes are appreciated. What's most needed is decentralization.So if you can, run a bare metal node from home\n",
      "\n",
      "score 0.623049259\n",
      "Not looked at yet, just wondering if any info on how to set up a fractus node\n",
      "\n",
      "score 0.587409914\n",
      "What would I need properly? In my country the internet is precarious for what each node needs\n"
     ]
    }
   ],
   "source": [
    "query = \"Node setup\"\n",
    "search_results(query, limit=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index initialization\n",
    "from semantic_search_generator import SemanticSearchGenerator\n",
    "\n",
    "channel_id = \"singularitynet\"\n",
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "INDEX_NAME = \"telegram-embeddings\"\n",
    "\n",
    "generator = SemanticSearchGenerator(model_name)\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=os.environ[\"PINECONE_APIKEY\"],\n",
    "    environment=\"us-west1-gcp\"\n",
    ")\n",
    "\n",
    "# connect to index\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt_template = \"\"\"Use the chat messages (not sorted in any particular order) below to answer the given user query:\n",
    "    messages_list: {messages}\n",
    "    query: {query}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"messages\", \"query\"])\n",
    "llm = OpenAIChat(temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_results(query, limit=50):\n",
    "    query_emb = generator.encode_messages(query)\n",
    "\n",
    "    results = index.query(\n",
    "      vector=query_emb.tolist(),\n",
    "      top_k=limit,\n",
    "      include_values=False,\n",
    "      include_metadata=True\n",
    "    )\n",
    "\n",
    "    messages = []\n",
    "    for item in results[\"matches\"]:\n",
    "        # print(f\"\\nscore {item['score']}\")\n",
    "        # print(item[\"metadata\"][\"clean_message\"])\n",
    "        messages.append(item[\"metadata\"][\"clean_message\"])\n",
    "\n",
    "    return messages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is good about this project?\"\n",
    "messages = search_results(query)\n",
    "inputs = [{\"message\": msg} for _, msg in zip(range(len(messages)), messages)]\n",
    "result = chain.run({\"messages\":inputs, \"query\":query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what do users complain about this project?\"\n",
    "messages = search_results(query)\n",
    "inputs = [{\"index\": i, \"message\": msg} for i, msg in zip(range(len(messages)), messages)]\n",
    "result = chain.run({\"messages\":inputs, \"query\":query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the open-source embedding function\n",
    "hf_embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# comput embeddings and load to chroma\n",
    "db = Chroma.from_documents(docs, hf_embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to query\n",
    "def search_db(db_client, query: str, top_k = 100):\n",
    "    docs = db_client.similarity_search(query, k=top_k)\n",
    "\n",
    "    # print results\n",
    "    for item in docs[:5]:\n",
    "        print(f\"\\n{item.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fosho\n",
      "\n",
      "seems like they 'RMI'  really FOMO'ing for this,  especially after reading the\n",
      "\n",
      "Hellyea\n",
      "\n",
      "saoyem Nice Francesco\n",
      "\n",
      "zealy\n"
     ]
    }
   ],
   "source": [
    "query = \"fomo\"\n",
    "search_db(db, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "client = Chroma.from_documents(\n",
    "    docs, \n",
    "    embedding_function, \n",
    "    client=persistent_client, \n",
    "    collection_name = f\"embeddings_collection_{channel_id[1:]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- User_1853540265: A coinbase listing would be bullish\n",
      "- User_6010276849: In a bear season as well this,  not sure there will be effect. Listing sometimes has been o do with the right timing as well. The hype is there, you list and boom up to the sky.\n",
      "\n",
      "- User_1460230397: We're thrilled to announce that the @xenergyweb Crowdloan on @Polkadot\n",
      " is now live! Join Energy Web in shaping the energy future and contribute.\n",
      "\n",
      "For more information about the Crowdloan, visit: https://crowdloan.energywebx.com\n",
      "\n",
      "Like and Retweet here: https://twitter.com/energywebx/status/1698820250643411030\n",
      "- User_5986732143: This crowdloan went so well!!! Cannot believe it‚Äôs a bear market at all.\n",
      "\n",
      "- User_1618131036: Another week went by. Hopefully the crypto market will recover soon\n",
      "- User_5418407519: I hope soo , we have endure bearish for a long time .\n",
      "\n",
      "- User_530622263: We are fortunate to be aware of such a great project during the last months of the bear market. A good time to dollar cost average IMO.\n",
      "- User_6448580728: Total agree\n",
      "\n",
      "- User_5454456997: Why day by day price go down?\n",
      "- User_6010276849: Happening to all it's the bear season, the best you can do for yourself mate is to wait for the bull run\n"
     ]
    }
   ],
   "source": [
    "query = \"bearish\"\n",
    "search_db(client, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-playground-K_szDW0O-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
