{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search on telegram channels\n",
    "\n",
    "Showcasing how to extract telegram messages for a specific channel and perform semantic search given an user query. \n",
    "I use pretrained models for semantic search from huggingface.\n",
    "\n",
    "The fetched messages are first embbeded with the model and then uploaded to a pinecode index. Then the query is embedded and compared against the indexed data.\n",
    "\n",
    "An option for future work is to fine tune a model specific for telegram messages of certain topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilo.ramirez/Library/Caches/pypoetry/virtualenvs/telegram-nlp-6m6KizWy-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "from telethon.sync import TelegramClient\n",
    "from IPython.display import display\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "import pinecone\n",
    "\n",
    "from telethon.tl.types import InputMessagesFilterEmpty\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# do not truncate column width in pandas\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_id = os.environ[\"TELEGRAM_API_ID\"]\n",
    "api_hash = os.environ[\"TELEGRAM_API_HASH\"]\n",
    "pinecone_key = os.environ[\"PINECONE_APIKEY\"]\n",
    "phone = \"+34634454832\"\n",
    "username = \"@elvesipeto\"\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fetching and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = []\n",
    "\n",
    "columns = [\"channel_name\", \"id\", \"peer_id\", \"date\", \"message\", \"out\", \"mentioned\",\n",
    "        \"media_unread\", \"silent\", \"post\", \"from_scheduled\", \"legacy\", \n",
    "        \"edit_hide\", \"pinned\",\"noforwards\", \"from_id\", \"fwd_from\", \"via_bot_id\",\n",
    "        \"reply_to\", \"media\", \"reply_markup\", \"entities\", \"views\",\n",
    "        \"forwards\", \"replies\", \"edit_date\", \"post_author\", \"grouped_id\",\n",
    "        \"reactions\", \"restriction_reason\", \"ttl_period\"]\n",
    "\n",
    "client = TelegramClient(f\"sessions_data/{phone}\", api_id, api_hash)\n",
    "channel_id = \"@runonflux\"\n",
    "n = 5000\n",
    "\n",
    "async with client:        \n",
    "    async for msg in client.iter_messages(channel_id, filter=InputMessagesFilterEmpty, limit=n):\n",
    "        pd_data.append((channel_id, msg.id,msg.peer_id, msg.date, msg.message,\n",
    "                msg.out, msg.mentioned, msg.media_unread, msg.silent,msg.post,\n",
    "                msg.from_scheduled, msg.legacy, msg.edit_hide, msg.pinned, msg.noforwards,\n",
    "                msg.from_id, msg.fwd_from, msg.via_bot_id, msg.reply_to, msg.media, msg.reply_markup,\n",
    "                msg.entities, msg.views, msg.forwards, msg.replies, msg.edit_date, msg.post_author,\n",
    "                msg.grouped_id, msg.reactions, msg.restriction_reason, msg.ttl_period\n",
    "        ))\n",
    "\n",
    "df = pd.DataFrame(pd_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total message count 5000\n",
      "Total messages after excluding empty 4848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10      1.00\n",
       "0.25      4.00\n",
       "0.50      9.00\n",
       "0.75     19.00\n",
       "0.95     56.00\n",
       "0.98    132.06\n",
       "Name: token_count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total messages after excluding long and short messages 3459\n",
      "Total messages after excluding duplicates 3117\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and filtering \n",
    "\n",
    "df[\"token_count\"] = df[\"message\"].apply(lambda x: len(x.split(\" \"))  if type(x) == str else 0)\n",
    "print(\"Total message count\", len(df))\n",
    "\n",
    "filtered_df = df[~df[\"message\"].isna()]\n",
    "print(\"Total messages after excluding empty\", len(filtered_df))\n",
    "\n",
    "# What is the distribution of token counts?\n",
    "display(filtered_df[\"token_count\"].quantile([.1, .25, .5, .75, .95, 0.98]))\n",
    "\n",
    "\n",
    "lower_limit = 4\n",
    "\n",
    "# 250 was the max input lenght of the training data for multi-qa-MiniLM-L6-cos-v1\n",
    "upper_limit = 250 \n",
    "\n",
    "filtered_df = filtered_df[(filtered_df[\"token_count\"] > lower_limit) & (filtered_df[\"token_count\"] < upper_limit)]\n",
    "print(\"Total messages after excluding long and short messages\", len(filtered_df))\n",
    "\n",
    "# clean messages\n",
    "filtered_df.loc[:, \"clean_message\"] = filtered_df[\"message\"].apply(lambda x: re.sub('[^A-Za-z0-9 .,?$%\\'\"]+', '', x))\n",
    "\n",
    "# remove duplicates\n",
    "filtered_df = filtered_df[~filtered_df.duplicated(subset=[\"clean_message\"])]\n",
    "print(\"Total messages after excluding duplicates\", len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv(f\"notebooks/data/{channel_id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from semantic_search_generator import SemanticSearchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This flux 4 upgrade made 6 of my nodes go offline.  Now is dos mode.How to get out if this please?',\n",
       " 'I would suggest you to stop promoting the group BettyK0',\n",
       " 'Yes deleting nodes because of low rewards is the most scary thing  we may even see less than 0.20 ',\n",
       " 'Join our CBO Davy Wittock for a special mining episode for Around the Blockchain today at 5 PM EST Get ready for an exciting discussion about Proof of Useful Work and the future of mining Link  httpsyoutube.comaroundtheblockchainofficial',\n",
       " ' many crypto projects are one sided in their community. Most are in discord, some are almost exclusively on telegram, some loosely on Twitter....',\n",
       " \"My buy in was 60c but I asked literally everyone big in the flux space if we could maintain the dollar and they were all bullish including Dan. I wanted to sell to buy back cheaper and am kicking myself I didn't lol\",\n",
       " \"What's command on TG Flux  to check amount stake titan node ?\",\n",
       " 'For example, my stratus gives me 110 a month with current price and APR. Cost of the dedicated server is 70.If i wanted to run cumulus instead, it would be 40 cumulus, giving me about 220 total a month, but costing me about 210 in VPS cost.Plus now i have to monitor and maintain 40 nodes instead of one ',\n",
       " 'Anybody withdraw Flux  from CoinEX?Looks suspended',\n",
       " 'We only have 400mil flux  was it an amount allocated for this parallel claims ?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_id = \"@runonflux\"\n",
    "df = pd.read_csv(f\"notebooks/data/{channel_id}.csv\")\n",
    "messages = df.sample(10, random_state=11)[\"clean_message\"].to_list()\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2212686538696289 My buy in was 60c but I asked literally everyone big in the flux space if we could maintain the dollar and they were all bullish including Dan. I wanted to sell to buy back cheaper and am kicking myself I didn't lol\n",
      "0.10311347246170044 For example, my stratus gives me 110 a month with current price and APR. Cost of the dedicated server is 70.If i wanted to run cumulus instead, it would be 40 cumulus, giving me about 220 total a month, but costing me about 210 in VPS cost.Plus now i have to monitor and maintain 40 nodes instead of one \n",
      "0.09914617985486984 Join our CBO Davy Wittock for a special mining episode for Around the Blockchain today at 5 PM EST Get ready for an exciting discussion about Proof of Useful Work and the future of mining Link  httpsyoutube.comaroundtheblockchainofficial\n",
      "0.08931327611207962 I would suggest you to stop promoting the group BettyK0\n",
      "0.06712281703948975 Anybody withdraw Flux  from CoinEX?Looks suspended\n",
      "0.04982435703277588  many crypto projects are one sided in their community. Most are in discord, some are almost exclusively on telegram, some loosely on Twitter....\n",
      "0.04696136713027954 Yes deleting nodes because of low rewards is the most scary thing  we may even see less than 0.20 \n",
      "-0.005718698725104332 We only have 400mil flux  was it an amount allocated for this parallel claims ?\n",
      "-0.024313876405358315 What's command on TG Flux  to check amount stake titan node ?\n",
      "-0.048260483890771866 This flux 4 upgrade made 6 of my nodes go offline.  Now is dos mode.How to get out if this please?\n"
     ]
    }
   ],
   "source": [
    "generator = SemanticSearchGenerator()\n",
    "\n",
    "# Text to encode\n",
    "query = \"investment strategy\"\n",
    "doc_score_pairs = generator.search_batch(query, messages, device=\"mps\")\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs[:10]:\n",
    "    print(score, doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = \"@runonflux\"\n",
    "model_name = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "df = pd.read_csv(f\"notebooks/data/{channel_id}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=os.environ[\"PINECONE_APIKEY\"],\n",
    "    environment=\"us-west1-gcp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings model\n",
    "multi_qa_encoder = SentenceTransformer(model_name)\n",
    "\n",
    "query = \"This coin will moon soon\"\n",
    "vec = multi_qa_encoder.encode(query, convert_to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_DELETE_INDEX = False # Set True only for initializing the index\n",
    "INDEX_NAME = \"telegram-embeddings\"\n",
    "\n",
    "if FORCE_DELETE_INDEX:\n",
    "    pinecone.delete_index(INDEX_NAME)\n",
    "\n",
    "if INDEX_NAME not in pinecone.list_indexes():\n",
    "    pinecone.create_index(INDEX_NAME, dimension=len(vec))\n",
    "    \n",
    "# connect to index\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    has_gpu = torch.cuda.is_available()\n",
    "    has_mps = torch.backends.mps.is_built()\n",
    "    device = \"mps\" if has_mps else \"gpu\" if has_gpu else \"cpu\"\n",
    "    return device\n",
    "\n",
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to index\n",
    "COMPUTE_EMBEDDINGS = True\n",
    "if COMPUTE_EMBEDDINGS:\n",
    "    # create embeddings\n",
    "    df[\"embeddings_cpu\"] = df[\"clean_message\"].apply(lambda x: multi_qa_encoder.encode(x, device=\"cpu\", convert_to_tensor=True, show_progress_bar=False))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SemanticSearchGenerator(model_name)\n",
    "\n",
    "# Faster with mps\n",
    "df[\"embeddings_mps\"] = df[\"clean_message\"].apply(lambda x: generator.encode_messages(x, device=\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings_cpu</th>\n",
       "      <th>embeddings_mps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tensor(-0.0749), tensor(-0.1107), tensor(-0.0339), tensor(0.0374), tensor(-0.0197), tensor(0.0569), tensor(0.0786), tensor(-0.0522), tensor(-0.0159), tensor(0.0207), tensor(-0.0155), tensor(-0.01...</td>\n",
       "      <td>[[tensor(-0.0749, device='mps:0'), tensor(-0.1107, device='mps:0'), tensor(-0.0339, device='mps:0'), tensor(0.0374, device='mps:0'), tensor(-0.0197, device='mps:0'), tensor(0.0569, device='mps:0')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tensor(0.0309), tensor(-0.0022), tensor(0.0416), tensor(0.0120), tensor(0.0061), tensor(0.0405), tensor(-0.1566), tensor(-0.0018), tensor(-0.1030), tensor(0.0587), tensor(0.0292), tensor(0.0281),...</td>\n",
       "      <td>[[tensor(0.0309, device='mps:0'), tensor(-0.0022, device='mps:0'), tensor(0.0416, device='mps:0'), tensor(0.0120, device='mps:0'), tensor(0.0061, device='mps:0'), tensor(0.0405, device='mps:0'), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tensor(0.0337), tensor(-0.0346), tensor(-0.0315), tensor(-0.0759), tensor(-0.0189), tensor(0.0352), tensor(-0.0644), tensor(0.0090), tensor(-0.0890), tensor(-0.0099), tensor(-0.1018), tensor(-0.0...</td>\n",
       "      <td>[[tensor(0.0337, device='mps:0'), tensor(-0.0346, device='mps:0'), tensor(-0.0315, device='mps:0'), tensor(-0.0759, device='mps:0'), tensor(-0.0189, device='mps:0'), tensor(0.0352, device='mps:0')...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                            embeddings_cpu  \\\n",
       "0  [tensor(-0.0749), tensor(-0.1107), tensor(-0.0339), tensor(0.0374), tensor(-0.0197), tensor(0.0569), tensor(0.0786), tensor(-0.0522), tensor(-0.0159), tensor(0.0207), tensor(-0.0155), tensor(-0.01...   \n",
       "1  [tensor(0.0309), tensor(-0.0022), tensor(0.0416), tensor(0.0120), tensor(0.0061), tensor(0.0405), tensor(-0.1566), tensor(-0.0018), tensor(-0.1030), tensor(0.0587), tensor(0.0292), tensor(0.0281),...   \n",
       "2  [tensor(0.0337), tensor(-0.0346), tensor(-0.0315), tensor(-0.0759), tensor(-0.0189), tensor(0.0352), tensor(-0.0644), tensor(0.0090), tensor(-0.0890), tensor(-0.0099), tensor(-0.1018), tensor(-0.0...   \n",
       "\n",
       "                                                                                                                                                                                            embeddings_mps  \n",
       "0  [[tensor(-0.0749, device='mps:0'), tensor(-0.1107, device='mps:0'), tensor(-0.0339, device='mps:0'), tensor(0.0374, device='mps:0'), tensor(-0.0197, device='mps:0'), tensor(0.0569, device='mps:0')...  \n",
       "1  [[tensor(0.0309, device='mps:0'), tensor(-0.0022, device='mps:0'), tensor(0.0416, device='mps:0'), tensor(0.0120, device='mps:0'), tensor(0.0061, device='mps:0'), tensor(0.0405, device='mps:0'), t...  \n",
       "2  [[tensor(0.0337, device='mps:0'), tensor(-0.0346, device='mps:0'), tensor(-0.0315, device='mps:0'), tensor(-0.0759, device='mps:0'), tensor(-0.0189, device='mps:0'), tensor(0.0352, device='mps:0')...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"embeddings_cpu\", \"embeddings_mps\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "UPLOAD_VECTORS = False # only for index initialization\n",
    "if UPLOAD_VECTORS:    \n",
    "    batch_size = 1000\n",
    "    total_batches = math.ceil(len(df) / batch_size)\n",
    "    start = 0\n",
    "\n",
    "    for i in range(total_batches):\n",
    "        index_upsert = [] # always initialize for each batch        \n",
    "        end = start + batch_size\n",
    "\n",
    "        print(f\"iterating messages {start}-{end}\")\n",
    "        for j, item in df[start:end].iterrows():\n",
    "            index_upsert += [\n",
    "                    (str(j), \n",
    "                    item[\"embeddings_cpu\"].tolist(),\n",
    "                    {\n",
    "                        \"clean_message\": item[\"clean_message\"],\n",
    "                        \"channel_name\": item[\"channel_name\"],\n",
    "                        \"messagee_id\": item[\"id\"]\n",
    "                    })\n",
    "            ]\n",
    "        start = end\n",
    "        print(f\"inserting batch {i}\")\n",
    "        index.upsert(vectors=index_upsert) # can contain maximum 1000 items        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_results(query, limit=20):\n",
    "    query_emb = generator.encode_messages(query)\n",
    "\n",
    "    results = index.query(\n",
    "      vector=query_emb.tolist(),\n",
    "      top_k=limit,\n",
    "      include_values=False,\n",
    "      include_metadata=True\n",
    "    )\n",
    "\n",
    "    messages = []\n",
    "    for item in results[\"matches\"]:\n",
    "        print(f\"\\nscore {item['score']}\")\n",
    "        print(item[\"metadata\"][\"clean_message\"])\n",
    "        messages.append(item[\"metadata\"][\"clean_message\"])\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.410763919\n",
      "Typical bear market... Engagement drops, people hesitate. Meanwhile the team continues to build, POUW just presented a couple of weeks ago\n",
      "\n",
      "score 0.401366264\n",
      "keep an eye on announcements\n",
      "\n",
      "score 0.387041956\n",
      "Nothing happened, bear markets are a bitch\n",
      "\n",
      "score 0.362539232\n",
      "If you interested list in our exchange I can help you\n",
      "\n",
      "score 0.350785732\n",
      "Bearmarkets dont last forever. Unless you are in a scam project. I dont see any other thing here than non stopping hardwork. So chill \n"
     ]
    }
   ],
   "source": [
    "query = \"bearish outlook\"\n",
    "search_results(query, limit=5);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.501404643\n",
      "Hey here A beautiful week to all, its amazing how when the market is bearing or in halt the vibes in communities change, you can see clearly the vision and the rational unlike in bull where everyone is jumping in without research\n",
      "\n",
      "score 0.4879556\n",
      "I've never been a fan of the bullish halving narrative, to many disappointed people who fell for the hype.\n",
      "\n",
      "score 0.407264948\n",
      "Who said anything about expecting a bull run ? I said i will cash out my flux when it hits 1$ again\n",
      "\n",
      "score 0.40503487\n",
      "Is there a bot's news function or roadmap?\n",
      "\n",
      "score 0.404052913\n",
      "I know what you mean but in bull it will be worthed\n",
      "\n",
      "score 0.403915346\n",
      "Of course but hopefully not until next bull run to maximise exposure\n",
      "\n",
      "score 0.400119781\n",
      " We're excited to introduce a new speaker, Daniel Weiss httpswww.linkedin.comindanielweissesqcpaHe will join a panel discussion on the topic \"The Heart of AI Governance, Data, and Society's Wellbeing\".Join us in Florida for our exciting Web3 event. Get your tickets now at httpscypherpunk2023.com\n",
      "\n",
      "score 0.3980802\n",
      "Great news  Should keep the circulating supply smaller now . Now only mining can increase it\n",
      "\n",
      "score 0.397279531\n",
      "Nothing happened, bear markets are a bitch\n",
      "\n",
      "score 0.38933146\n",
      "I am guessing the hostnodes people are even more upset now \n",
      "\n",
      "score 0.388903707\n",
      "keep an eye on announcements\n",
      "\n",
      "score 0.381805092\n",
      "Could thek team make some announcements show ambitions and push the real thing\n",
      "\n",
      "score 0.378582537\n",
      "So hyped for this event\n",
      "\n",
      "score 0.376104176\n",
      " Thrilled to announce new cypherpunk2023 speaker, Samuel Armes, delving into \"The Politics of CBDCs.\"Don't miss out on this exciting Web3 conference, happening on Sep. 2728 in Florida Secure your ticket at httpscypherpunk2023.com.\n",
      "\n",
      "score 0.375007361\n",
      "soon  wait for announcement\n",
      "\n",
      "score 0.371853083\n",
      "Someone pumped it before the official announcement\n",
      "\n",
      "score 0.362896532\n",
      "$10 in bull is almost guaranteed given the product and revenue growth imho. Short term I am concerned for node losses if we go much lower .10 as you mention would be very bad for node retention.\n",
      "\n",
      "score 0.362876\n",
      " releasing an article about it soon\n",
      "\n",
      "score 0.362059325\n",
      "no announcement yet  should be within a few hours i guess...\n",
      "\n",
      "score 0.353994638\n",
      " Exciting news FLUX is now listed on the US exchange UpholdInc.This move not only solidifies our commitment to regulatory compliance but also broadens the horizons for our USbased community members.Expanding secure trading options. Stay tuned for updates and happy trading httpsuphold.com\n"
     ]
    }
   ],
   "source": [
    "query = \"bullish news\"\n",
    "search_results(query);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.790179\n",
      "there is no pouw yet  whats the question?\n",
      "\n",
      "score 0.697877347\n",
      "Pouw isn't even live yet.Also there's still a lot of hardware available i think the network is at 40% right now\n",
      "\n",
      "score 0.691974163\n",
      "Hi guys what is the latest re. POuW?\n",
      "\n",
      "score 0.682593167\n",
      "Hi , you can discuss PoUW in the mining section. All news will be in the announcements section.\n",
      "\n",
      "score 0.659035504\n",
      "Not atm.. Pouw coming towards end of the year\n"
     ]
    }
   ],
   "source": [
    "query = \"PouW\"\n",
    "search_results(query, limit=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.661882877\n",
      "make some node will be fine\n",
      "\n",
      "score 0.655703783\n",
      "If you create the node as privileged it should be good from the start\n",
      "\n",
      "score 0.6469993\n",
      "All nodes are appreciated. What's most needed is decentralization.So if you can, run a bare metal node from home\n",
      "\n",
      "score 0.623049259\n",
      "Not looked at yet, just wondering if any info on how to set up a fractus node\n",
      "\n",
      "score 0.587409914\n",
      "What would I need properly? In my country the internet is precarious for what each node needs\n"
     ]
    }
   ],
   "source": [
    "query = \"Node setup\"\n",
    "search_results(query, limit=5);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-playground-K_szDW0O-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
