{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search on telegram channels\n",
    "\n",
    "Showcasing how to extract telegram messages for a specific channel and perform semantic search given an user query. \n",
    "I use pretrained models for semantic search from huggingface.\n",
    "\n",
    "The fetched messages are first embbeded with the model and then uploaded to a pinecode index. Then the query is embedded and compared against the indexed data.\n",
    "\n",
    "An option for future work is to fine tune a model specific for telegram messages of certain topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "from telethon.sync import TelegramClient\n",
    "from IPython.display import display\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "import pinecone\n",
    "\n",
    "from telethon.tl.types import InputMessagesFilterEmpty\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# do not truncate column width in pandas\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_id = os.environ[\"TELEGRAM_API_ID\"]\n",
    "api_hash = os.environ[\"TELEGRAM_API_HASH\"]\n",
    "pinecone_key = os.environ[\"PINECONE_APIKEY\"]\n",
    "phone = \"+34634454832\"\n",
    "username = \"@elvesipeto\"\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fetching and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = []\n",
    "\n",
    "columns = [\"channel_name\", \"id\", \"peer_id\", \"date\", \"message\", \"out\", \"mentioned\",\n",
    "        \"media_unread\", \"silent\", \"post\", \"from_scheduled\", \"legacy\", \n",
    "        \"edit_hide\", \"pinned\",\"noforwards\", \"from_id\", \"fwd_from\", \"via_bot_id\",\n",
    "        \"reply_to\", \"media\", \"reply_markup\", \"entities\", \"views\",\n",
    "        \"forwards\", \"replies\", \"edit_date\", \"post_author\", \"grouped_id\",\n",
    "        \"reactions\", \"restriction_reason\", \"ttl_period\"]\n",
    "\n",
    "client = TelegramClient(f\"sessions_data/{phone}\", api_id, api_hash)\n",
    "channel_id = \"@energyweb\"\n",
    "n = 10000\n",
    "\n",
    "async with client:        \n",
    "    async for msg in client.iter_messages(channel_id, filter=InputMessagesFilterEmpty, limit=n):\n",
    "        try:\n",
    "            pd_data.append((channel_id, msg.id, msg.peer_id, msg.date, msg.message,\n",
    "                    msg.out, msg.mentioned, msg.media_unread, msg.silent,msg.post,\n",
    "                    msg.from_scheduled, msg.legacy, msg.edit_hide, msg.pinned, msg.noforwards,\n",
    "                    msg.from_id.user_id if hasattr(msg.from_id, \"user_id\") else msg.from_id.channel_id, msg.fwd_from, msg.via_bot_id, msg.reply_to, msg.media, msg.reply_markup,\n",
    "                    msg.entities, msg.views, msg.forwards, msg.replies, msg.edit_date, msg.post_author,\n",
    "                    msg.grouped_id, msg.reactions, msg.restriction_reason, msg.ttl_period\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(msg.from_id)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>peer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>out</th>\n",
       "      <th>mentioned</th>\n",
       "      <th>media_unread</th>\n",
       "      <th>silent</th>\n",
       "      <th>post</th>\n",
       "      <th>from_scheduled</th>\n",
       "      <th>legacy</th>\n",
       "      <th>edit_hide</th>\n",
       "      <th>pinned</th>\n",
       "      <th>noforwards</th>\n",
       "      <th>from_id</th>\n",
       "      <th>fwd_from</th>\n",
       "      <th>via_bot_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>media</th>\n",
       "      <th>reply_markup</th>\n",
       "      <th>entities</th>\n",
       "      <th>views</th>\n",
       "      <th>forwards</th>\n",
       "      <th>replies</th>\n",
       "      <th>edit_date</th>\n",
       "      <th>post_author</th>\n",
       "      <th>grouped_id</th>\n",
       "      <th>reactions</th>\n",
       "      <th>restriction_reason</th>\n",
       "      <th>ttl_period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_name</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">@energyweb</th>\n",
       "      <th>327093</th>\n",
       "      <td>PeerChannel(channel_id=1116232376)</td>\n",
       "      <td>2023-10-20 15:59:38+00:00</td>\n",
       "      <td>@a84765641 [6401503585] to be accepted in the group, please subscribe to our channel. Once joined, click the button below. \\nAction: Muted üîá until 22/10/2023 17:59.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5297034533</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MessageReplyHeader(reply_to_msg_id=327092, reply_to_scheduled=False, forum_topic=False, reply_to_peer_id=None, reply_to_top_id=None)</td>\n",
       "      <td>None</td>\n",
       "      <td>ReplyInlineMarkup(rows=[KeyboardButtonRow(buttons=[KeyboardButtonUrl(text='üì£ Subscribe to channel', url='http://t.me/EnergyWebAnnouncements')]), KeyboardButtonRow(buttons=[KeyboardButtonCallback(t...</td>\n",
       "      <td>[MessageEntityMentionName(offset=0, length=10, user_id=6401503585), MessageEntityCode(offset=12, length=10), MessageEntityTextUrl(offset=70, length=14, url='http://t.me/EnergyWebAnnouncements'), M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327091</th>\n",
       "      <td>PeerChannel(channel_id=1116232376)</td>\n",
       "      <td>2023-10-20 15:56:15+00:00</td>\n",
       "      <td>üëãüèªüëãüèª</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1174003449</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReplies(replies=0, replies_pts=520340, comments=False, recent_repliers=[], channel_id=None, max_id=None, read_max_id=None)</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                peer_id  \\\n",
       "channel_name id                                           \n",
       "@energyweb   327093  PeerChannel(channel_id=1116232376)   \n",
       "             327091  PeerChannel(channel_id=1116232376)   \n",
       "\n",
       "                                         date  \\\n",
       "channel_name id                                 \n",
       "@energyweb   327093 2023-10-20 15:59:38+00:00   \n",
       "             327091 2023-10-20 15:56:15+00:00   \n",
       "\n",
       "                                                                                                                                                                                  message  \\\n",
       "channel_name id                                                                                                                                                                             \n",
       "@energyweb   327093  @a84765641 [6401503585] to be accepted in the group, please subscribe to our channel. Once joined, click the button below. \\nAction: Muted üîá until 22/10/2023 17:59.   \n",
       "             327091                                                                                                                                                                  üëãüèªüëãüèª   \n",
       "\n",
       "                       out  mentioned  media_unread  silent   post  \\\n",
       "channel_name id                                                      \n",
       "@energyweb   327093  False      False         False    True  False   \n",
       "             327091  False      False         False   False  False   \n",
       "\n",
       "                     from_scheduled  legacy  edit_hide  pinned  noforwards  \\\n",
       "channel_name id                                                              \n",
       "@energyweb   327093           False   False      False   False       False   \n",
       "             327091           False   False      False   False       False   \n",
       "\n",
       "                        from_id fwd_from via_bot_id  \\\n",
       "channel_name id                                       \n",
       "@energyweb   327093  5297034533     None       None   \n",
       "             327091  1174003449     None       None   \n",
       "\n",
       "                                                                                                                                                 reply_to  \\\n",
       "channel_name id                                                                                                                                             \n",
       "@energyweb   327093  MessageReplyHeader(reply_to_msg_id=327092, reply_to_scheduled=False, forum_topic=False, reply_to_peer_id=None, reply_to_top_id=None)   \n",
       "             327091                                                                                                                                  None   \n",
       "\n",
       "                    media  \\\n",
       "channel_name id             \n",
       "@energyweb   327093  None   \n",
       "             327091  None   \n",
       "\n",
       "                                                                                                                                                                                                                reply_markup  \\\n",
       "channel_name id                                                                                                                                                                                                                \n",
       "@energyweb   327093  ReplyInlineMarkup(rows=[KeyboardButtonRow(buttons=[KeyboardButtonUrl(text='üì£ Subscribe to channel', url='http://t.me/EnergyWebAnnouncements')]), KeyboardButtonRow(buttons=[KeyboardButtonCallback(t...   \n",
       "             327091                                                                                                                                                                                                     None   \n",
       "\n",
       "                                                                                                                                                                                                                    entities  \\\n",
       "channel_name id                                                                                                                                                                                                                \n",
       "@energyweb   327093  [MessageEntityMentionName(offset=0, length=10, user_id=6401503585), MessageEntityCode(offset=12, length=10), MessageEntityTextUrl(offset=70, length=14, url='http://t.me/EnergyWebAnnouncements'), M...   \n",
       "             327091                                                                                                                                                                                                     None   \n",
       "\n",
       "                     views  forwards  \\\n",
       "channel_name id                        \n",
       "@energyweb   327093    NaN       NaN   \n",
       "             327091    NaN       NaN   \n",
       "\n",
       "                                                                                                                                               replies  \\\n",
       "channel_name id                                                                                                                                          \n",
       "@energyweb   327093                                                                                                                               None   \n",
       "             327091  MessageReplies(replies=0, replies_pts=520340, comments=False, recent_repliers=[], channel_id=None, max_id=None, read_max_id=None)   \n",
       "\n",
       "                    edit_date post_author  grouped_id reactions  \\\n",
       "channel_name id                                                   \n",
       "@energyweb   327093       NaT        None         NaN      None   \n",
       "             327091       NaT        None         NaN      None   \n",
       "\n",
       "                    restriction_reason ttl_period  \n",
       "channel_name id                                    \n",
       "@energyweb   327093               None       None  \n",
       "             327091               None       None  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pd_data, columns=columns)\n",
    "df = df.set_index([\"channel_name\", \"id\"])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "def extract_reply_id(val):\n",
    "    \"\"\" search for the matching id\n",
    "    \"\"\"\n",
    "    if isinstance(val, str):\n",
    "        match = re.search(r'reply_to_msg_id=(\\d+)', val)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def compute_message_historical(df):\n",
    "    # compute message history for each message if available\n",
    "\n",
    "    df_extended = df.copy()\n",
    "    df_extended[\"in_history\"] = False\n",
    "    df_extended[\"reply_to_msg_id\"] = df_extended[\"reply_to\"].apply(lambda x: int(x.reply_to_msg_id) if x is not None else None)\n",
    "\n",
    "    # Only use if Class was parsed from text\n",
    "    # df['reply_to_msg_id'] = df['reply_to'].apply(extract_reply_id)\n",
    "    \n",
    "    for (channel_name, message_id), row in df_extended.iterrows():\n",
    "        history = [f\"User_{row['from_id']}: {row['message']}\"] # Initialize historical with current message\n",
    "        reply_id = row[\"reply_to_msg_id\"]\n",
    "        \n",
    "        try:\n",
    "            while not np.isnan(reply_id) and (channel_name, reply_id) in df_extended.index:\n",
    "                df_extended.loc[(channel_name, reply_id), \"in_history\"] = True\n",
    "                reply_row = df_extended.loc[(channel_name, reply_id)]\n",
    "                history.append(f\"User_{reply_row['from_id']}: {reply_row['message']}\")\n",
    "                reply_id = reply_row[\"reply_to_msg_id\"]\n",
    "        except Exception as e:\n",
    "            print(type(reply_id))\n",
    "            print(\"something failed\", e)\n",
    "\n",
    "        df_extended.loc[(channel_name, message_id), \"history\"] = str(history[::-1])\n",
    "\n",
    "    df_extended[\"history\"] = df_extended[\"history\"].apply(ast.literal_eval)\n",
    "    df_extended[\"history_str\"] = df_extended[\"history\"].apply(lambda x: \"- \" + \"\\n- \".join(x))\n",
    "    df_extended[\"thread_length\"] = df_extended[\"history\"].str.len()\n",
    "    return df_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plus = compute_message_historical(df)\n",
    "# print(df_plus[df_plus['history'].apply(lambda x: len(x) > 1)].iloc[0][\"history_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total message count 10000\n",
      "Total messages after excluding empty 10000\n",
      "token count distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10     1.0\n",
       "0.25     3.0\n",
       "0.50     7.0\n",
       "0.75    15.0\n",
       "0.95    40.0\n",
       "0.98    60.0\n",
       "Name: token_count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total messages after excluding long and short messages 9977\n",
      "Total messages after excluding duplicates 8763\n",
      "history tokens distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10      5.0\n",
       "0.25      8.0\n",
       "0.50     15.0\n",
       "0.75     30.0\n",
       "0.95     80.0\n",
       "0.98    115.0\n",
       "Name: history_token_count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread length distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10    1.0\n",
       "0.25    1.0\n",
       "0.50    1.0\n",
       "0.75    2.0\n",
       "0.95    4.0\n",
       "0.98    5.0\n",
       "Name: thread_length, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count after excluding history duplicates\n",
      "6469\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and filtering \n",
    "\n",
    "df_plus[\"token_count\"] = df_plus[\"message\"].apply(lambda x: len(x.split(\" \"))  if type(x) == str else 0)\n",
    "print(\"Total message count\", len(df_plus))\n",
    "\n",
    "filtered_df = df_plus[~df_plus[\"message\"].isna()]\n",
    "print(\"Total messages after excluding empty\", len(filtered_df))\n",
    "\n",
    "# What is the distribution of token counts?\n",
    "print(\"token count distribution\")\n",
    "display(filtered_df[\"token_count\"].quantile([.1, .25, .5, .75, .95, 0.98]))\n",
    "\n",
    "\n",
    "lower_limit = 0\n",
    "\n",
    "# 250 was the max input lenght of the training data for multi-qa-MiniLM-L6-cos-v1 but looking at the length distribution this covers more than 99% of the messages\n",
    "upper_limit = 250 \n",
    "\n",
    "filtered_df = filtered_df[(filtered_df[\"token_count\"] > lower_limit) & (filtered_df[\"token_count\"] < upper_limit)]\n",
    "print(\"Total messages after excluding long and short messages\", len(filtered_df))\n",
    "\n",
    "# clean messages\n",
    "filtered_df.loc[:, \"clean_message\"] = filtered_df[\"message\"].apply(lambda x: re.sub('[^A-Za-z0-9 .,?$%\\'\"]+', '', x))\n",
    "\n",
    "# clean messages history\n",
    "filtered_df.loc[:, \"clean_message_history\"] = filtered_df[\"history_str\"].apply(lambda x: re.sub('[^A-Za-z0-9 .,?$%\\'\"]+', '', x))\n",
    "\n",
    "# remove duplicates\n",
    "filtered_df = filtered_df[~filtered_df.duplicated(subset=[\"clean_message\"])]\n",
    "print(\"Total messages after excluding duplicates\", len(filtered_df))\n",
    "\n",
    "filtered_df[\"history_token_count\"] = filtered_df[\"clean_message_history\"].apply(lambda x: len(x.split(\" \"))  if type(x) == str else 0)\n",
    "\n",
    "# What is the distribution of the tokens in the historical?\n",
    "print(\"history tokens distribution\")\n",
    "display(filtered_df[\"history_token_count\"].quantile([.1, .25, .5, .75, .95, 0.98]))\n",
    "\n",
    "# What is the distribution of the thread lenghts?\n",
    "print(\"thread length distribution\")\n",
    "display(filtered_df[\"thread_length\"].quantile([.1, .25, .5, .75, .95, 0.98]))\n",
    "\n",
    "print(\"count after excluding history duplicates\")\n",
    "filtered_df = filtered_df[~filtered_df[\"in_history\"]]\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv(f\"notebooks/data/{channel_id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from semantic_search_generator import SemanticSearchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This flux 4 upgrade made 6 of my nodes go offline.  Now is dos mode.How to get out if this please?',\n",
       " 'I would suggest you to stop promoting the group BettyK0',\n",
       " 'Yes deleting nodes because of low rewards is the most scary thing  we may even see less than 0.20 ',\n",
       " 'Join our CBO Davy Wittock for a special mining episode for Around the Blockchain today at 5 PM EST Get ready for an exciting discussion about Proof of Useful Work and the future of mining Link  httpsyoutube.comaroundtheblockchainofficial',\n",
       " ' many crypto projects are one sided in their community. Most are in discord, some are almost exclusively on telegram, some loosely on Twitter....',\n",
       " \"My buy in was 60c but I asked literally everyone big in the flux space if we could maintain the dollar and they were all bullish including Dan. I wanted to sell to buy back cheaper and am kicking myself I didn't lol\",\n",
       " \"What's command on TG Flux  to check amount stake titan node ?\",\n",
       " 'For example, my stratus gives me 110 a month with current price and APR. Cost of the dedicated server is 70.If i wanted to run cumulus instead, it would be 40 cumulus, giving me about 220 total a month, but costing me about 210 in VPS cost.Plus now i have to monitor and maintain 40 nodes instead of one ',\n",
       " 'Anybody withdraw Flux  from CoinEX?Looks suspended',\n",
       " 'We only have 400mil flux  was it an amount allocated for this parallel claims ?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_id = \"@runonflux\"\n",
    "df = pd.read_csv(f\"notebooks/data/{channel_id}.csv\")\n",
    "messages = df.sample(10, random_state=11)[\"clean_message\"].to_list()\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2212686538696289 My buy in was 60c but I asked literally everyone big in the flux space if we could maintain the dollar and they were all bullish including Dan. I wanted to sell to buy back cheaper and am kicking myself I didn't lol\n",
      "0.10311347246170044 For example, my stratus gives me 110 a month with current price and APR. Cost of the dedicated server is 70.If i wanted to run cumulus instead, it would be 40 cumulus, giving me about 220 total a month, but costing me about 210 in VPS cost.Plus now i have to monitor and maintain 40 nodes instead of one \n",
      "0.09914617985486984 Join our CBO Davy Wittock for a special mining episode for Around the Blockchain today at 5 PM EST Get ready for an exciting discussion about Proof of Useful Work and the future of mining Link  httpsyoutube.comaroundtheblockchainofficial\n",
      "0.08931327611207962 I would suggest you to stop promoting the group BettyK0\n",
      "0.06712281703948975 Anybody withdraw Flux  from CoinEX?Looks suspended\n",
      "0.04982435703277588  many crypto projects are one sided in their community. Most are in discord, some are almost exclusively on telegram, some loosely on Twitter....\n",
      "0.04696136713027954 Yes deleting nodes because of low rewards is the most scary thing  we may even see less than 0.20 \n",
      "-0.005718698725104332 We only have 400mil flux  was it an amount allocated for this parallel claims ?\n",
      "-0.024313876405358315 What's command on TG Flux  to check amount stake titan node ?\n",
      "-0.048260483890771866 This flux 4 upgrade made 6 of my nodes go offline.  Now is dos mode.How to get out if this please?\n"
     ]
    }
   ],
   "source": [
    "generator = SemanticSearchGenerator()\n",
    "\n",
    "# Text to encode\n",
    "query = \"investment strategy\"\n",
    "doc_score_pairs = generator.search_batch(query, messages, device=\"mps\")\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs[:10]:\n",
    "    print(score, doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = \"@runonflux\"\n",
    "model_name = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "df = pd.read_csv(f\"notebooks/data/{channel_id}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=os.environ[\"PINECONE_APIKEY\"],\n",
    "    environment=\"us-west1-gcp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings model\n",
    "multi_qa_encoder = SentenceTransformer(model_name)\n",
    "\n",
    "query = \"This coin will moon soon\"\n",
    "vec = multi_qa_encoder.encode(query, convert_to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_DELETE_INDEX = False # Set True only for initializing the index\n",
    "INDEX_NAME = \"telegram-embeddings\"\n",
    "\n",
    "if FORCE_DELETE_INDEX:\n",
    "    pinecone.delete_index(INDEX_NAME)\n",
    "\n",
    "if INDEX_NAME not in pinecone.list_indexes():\n",
    "    pinecone.create_index(INDEX_NAME, dimension=len(vec))\n",
    "    \n",
    "# connect to index\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    has_gpu = torch.cuda.is_available()\n",
    "    has_mps = torch.backends.mps.is_built()\n",
    "    device = \"mps\" if has_mps else \"gpu\" if has_gpu else \"cpu\"\n",
    "    return device\n",
    "\n",
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to index\n",
    "COMPUTE_EMBEDDINGS = True\n",
    "if COMPUTE_EMBEDDINGS:\n",
    "    # create embeddings\n",
    "    df[\"embeddings_cpu\"] = df[\"clean_message\"].apply(lambda x: multi_qa_encoder.encode(x, device=\"cpu\", convert_to_tensor=True, show_progress_bar=False))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SemanticSearchGenerator(model_name)\n",
    "\n",
    "# Faster with mps\n",
    "df[\"embeddings_mps\"] = df[\"clean_message\"].apply(lambda x: generator.encode_messages(x, device=\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings_cpu</th>\n",
       "      <th>embeddings_mps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tensor(-0.0749), tensor(-0.1107), tensor(-0.0339), tensor(0.0374), tensor(-0.0197), tensor(0.0569), tensor(0.0786), tensor(-0.0522), tensor(-0.0159), tensor(0.0207), tensor(-0.0155), tensor(-0.01...</td>\n",
       "      <td>[[tensor(-0.0749, device='mps:0'), tensor(-0.1107, device='mps:0'), tensor(-0.0339, device='mps:0'), tensor(0.0374, device='mps:0'), tensor(-0.0197, device='mps:0'), tensor(0.0569, device='mps:0')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tensor(0.0309), tensor(-0.0022), tensor(0.0416), tensor(0.0120), tensor(0.0061), tensor(0.0405), tensor(-0.1566), tensor(-0.0018), tensor(-0.1030), tensor(0.0587), tensor(0.0292), tensor(0.0281),...</td>\n",
       "      <td>[[tensor(0.0309, device='mps:0'), tensor(-0.0022, device='mps:0'), tensor(0.0416, device='mps:0'), tensor(0.0120, device='mps:0'), tensor(0.0061, device='mps:0'), tensor(0.0405, device='mps:0'), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tensor(0.0337), tensor(-0.0346), tensor(-0.0315), tensor(-0.0759), tensor(-0.0189), tensor(0.0352), tensor(-0.0644), tensor(0.0090), tensor(-0.0890), tensor(-0.0099), tensor(-0.1018), tensor(-0.0...</td>\n",
       "      <td>[[tensor(0.0337, device='mps:0'), tensor(-0.0346, device='mps:0'), tensor(-0.0315, device='mps:0'), tensor(-0.0759, device='mps:0'), tensor(-0.0189, device='mps:0'), tensor(0.0352, device='mps:0')...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                            embeddings_cpu  \\\n",
       "0  [tensor(-0.0749), tensor(-0.1107), tensor(-0.0339), tensor(0.0374), tensor(-0.0197), tensor(0.0569), tensor(0.0786), tensor(-0.0522), tensor(-0.0159), tensor(0.0207), tensor(-0.0155), tensor(-0.01...   \n",
       "1  [tensor(0.0309), tensor(-0.0022), tensor(0.0416), tensor(0.0120), tensor(0.0061), tensor(0.0405), tensor(-0.1566), tensor(-0.0018), tensor(-0.1030), tensor(0.0587), tensor(0.0292), tensor(0.0281),...   \n",
       "2  [tensor(0.0337), tensor(-0.0346), tensor(-0.0315), tensor(-0.0759), tensor(-0.0189), tensor(0.0352), tensor(-0.0644), tensor(0.0090), tensor(-0.0890), tensor(-0.0099), tensor(-0.1018), tensor(-0.0...   \n",
       "\n",
       "                                                                                                                                                                                            embeddings_mps  \n",
       "0  [[tensor(-0.0749, device='mps:0'), tensor(-0.1107, device='mps:0'), tensor(-0.0339, device='mps:0'), tensor(0.0374, device='mps:0'), tensor(-0.0197, device='mps:0'), tensor(0.0569, device='mps:0')...  \n",
       "1  [[tensor(0.0309, device='mps:0'), tensor(-0.0022, device='mps:0'), tensor(0.0416, device='mps:0'), tensor(0.0120, device='mps:0'), tensor(0.0061, device='mps:0'), tensor(0.0405, device='mps:0'), t...  \n",
       "2  [[tensor(0.0337, device='mps:0'), tensor(-0.0346, device='mps:0'), tensor(-0.0315, device='mps:0'), tensor(-0.0759, device='mps:0'), tensor(-0.0189, device='mps:0'), tensor(0.0352, device='mps:0')...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"embeddings_cpu\", \"embeddings_mps\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "UPLOAD_VECTORS = False # only for index initialization\n",
    "if UPLOAD_VECTORS:    \n",
    "    batch_size = 1000\n",
    "    total_batches = math.ceil(len(df) / batch_size)\n",
    "    start = 0\n",
    "\n",
    "    for i in range(total_batches):\n",
    "        index_upsert = [] # always initialize for each batch        \n",
    "        end = start + batch_size\n",
    "\n",
    "        print(f\"iterating messages {start}-{end}\")\n",
    "        for j, item in df[start:end].iterrows():\n",
    "            index_upsert += [\n",
    "                    (str(j), \n",
    "                    item[\"embeddings_cpu\"].tolist(),\n",
    "                    {\n",
    "                        \"clean_message\": item[\"clean_message\"],\n",
    "                        \"channel_name\": item[\"channel_name\"],\n",
    "                        \"messagee_id\": item[\"id\"]\n",
    "                    })\n",
    "            ]\n",
    "        start = end\n",
    "        print(f\"inserting batch {i}\")\n",
    "        index.upsert(vectors=index_upsert) # can contain maximum 1000 items        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_results(query, limit=20):\n",
    "    query_emb = generator.encode_messages(query)\n",
    "\n",
    "    results = index.query(\n",
    "      vector=query_emb.tolist(),\n",
    "      top_k=limit,\n",
    "      include_values=False,\n",
    "      include_metadata=True\n",
    "    )\n",
    "\n",
    "    messages = []\n",
    "    for item in results[\"matches\"]:\n",
    "        print(f\"\\nscore {item['score']}\")\n",
    "        print(item[\"metadata\"][\"clean_message\"])\n",
    "        messages.append(item[\"metadata\"][\"clean_message\"])\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.410763919\n",
      "Typical bear market... Engagement drops, people hesitate. Meanwhile the team continues to build, POUW just presented a couple of weeks ago\n",
      "\n",
      "score 0.401366264\n",
      "keep an eye on announcements\n",
      "\n",
      "score 0.387041956\n",
      "Nothing happened, bear markets are a bitch\n",
      "\n",
      "score 0.362539232\n",
      "If you interested list in our exchange I can help you\n",
      "\n",
      "score 0.350785732\n",
      "Bearmarkets dont last forever. Unless you are in a scam project. I dont see any other thing here than non stopping hardwork. So chill \n"
     ]
    }
   ],
   "source": [
    "query = \"bearish outlook\"\n",
    "search_results(query, limit=5);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.501404643\n",
      "Hey here A beautiful week to all, its amazing how when the market is bearing or in halt the vibes in communities change, you can see clearly the vision and the rational unlike in bull where everyone is jumping in without research\n",
      "\n",
      "score 0.4879556\n",
      "I've never been a fan of the bullish halving narrative, to many disappointed people who fell for the hype.\n",
      "\n",
      "score 0.407264948\n",
      "Who said anything about expecting a bull run ? I said i will cash out my flux when it hits 1$ again\n",
      "\n",
      "score 0.40503487\n",
      "Is there a bot's news function or roadmap?\n",
      "\n",
      "score 0.404052913\n",
      "I know what you mean but in bull it will be worthed\n",
      "\n",
      "score 0.403915346\n",
      "Of course but hopefully not until next bull run to maximise exposure\n",
      "\n",
      "score 0.400119781\n",
      " We're excited to introduce a new speaker, Daniel Weiss httpswww.linkedin.comindanielweissesqcpaHe will join a panel discussion on the topic \"The Heart of AI Governance, Data, and Society's Wellbeing\".Join us in Florida for our exciting Web3 event. Get your tickets now at httpscypherpunk2023.com\n",
      "\n",
      "score 0.3980802\n",
      "Great news  Should keep the circulating supply smaller now . Now only mining can increase it\n",
      "\n",
      "score 0.397279531\n",
      "Nothing happened, bear markets are a bitch\n",
      "\n",
      "score 0.38933146\n",
      "I am guessing the hostnodes people are even more upset now \n",
      "\n",
      "score 0.388903707\n",
      "keep an eye on announcements\n",
      "\n",
      "score 0.381805092\n",
      "Could thek team make some announcements show ambitions and push the real thing\n",
      "\n",
      "score 0.378582537\n",
      "So hyped for this event\n",
      "\n",
      "score 0.376104176\n",
      " Thrilled to announce new cypherpunk2023 speaker, Samuel Armes, delving into \"The Politics of CBDCs.\"Don't miss out on this exciting Web3 conference, happening on Sep. 2728 in Florida Secure your ticket at httpscypherpunk2023.com.\n",
      "\n",
      "score 0.375007361\n",
      "soon  wait for announcement\n",
      "\n",
      "score 0.371853083\n",
      "Someone pumped it before the official announcement\n",
      "\n",
      "score 0.362896532\n",
      "$10 in bull is almost guaranteed given the product and revenue growth imho. Short term I am concerned for node losses if we go much lower .10 as you mention would be very bad for node retention.\n",
      "\n",
      "score 0.362876\n",
      " releasing an article about it soon\n",
      "\n",
      "score 0.362059325\n",
      "no announcement yet  should be within a few hours i guess...\n",
      "\n",
      "score 0.353994638\n",
      " Exciting news FLUX is now listed on the US exchange UpholdInc.This move not only solidifies our commitment to regulatory compliance but also broadens the horizons for our USbased community members.Expanding secure trading options. Stay tuned for updates and happy trading httpsuphold.com\n"
     ]
    }
   ],
   "source": [
    "query = \"bullish news\"\n",
    "search_results(query);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.790179\n",
      "there is no pouw yet  whats the question?\n",
      "\n",
      "score 0.697877347\n",
      "Pouw isn't even live yet.Also there's still a lot of hardware available i think the network is at 40% right now\n",
      "\n",
      "score 0.691974163\n",
      "Hi guys what is the latest re. POuW?\n",
      "\n",
      "score 0.682593167\n",
      "Hi , you can discuss PoUW in the mining section. All news will be in the announcements section.\n",
      "\n",
      "score 0.659035504\n",
      "Not atm.. Pouw coming towards end of the year\n"
     ]
    }
   ],
   "source": [
    "query = \"PouW\"\n",
    "search_results(query, limit=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score 0.661882877\n",
      "make some node will be fine\n",
      "\n",
      "score 0.655703783\n",
      "If you create the node as privileged it should be good from the start\n",
      "\n",
      "score 0.6469993\n",
      "All nodes are appreciated. What's most needed is decentralization.So if you can, run a bare metal node from home\n",
      "\n",
      "score 0.623049259\n",
      "Not looked at yet, just wondering if any info on how to set up a fractus node\n",
      "\n",
      "score 0.587409914\n",
      "What would I need properly? In my country the internet is precarious for what each node needs\n"
     ]
    }
   ],
   "source": [
    "query = \"Node setup\"\n",
    "search_results(query, limit=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index initialization\n",
    "from semantic_search_generator import SemanticSearchGenerator\n",
    "\n",
    "channel_id = \"@runonflux\"\n",
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "INDEX_NAME = \"telegram-embeddings\"\n",
    "\n",
    "generator = SemanticSearchGenerator(model_name)\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=os.environ[\"PINECONE_APIKEY\"],\n",
    "    environment=\"us-west1-gcp\"\n",
    ")\n",
    "\n",
    "# connect to index\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt_template = \"\"\"Use the chat messages (not sorted in any particular order) below to answer the given user query:\n",
    "    messages_list: {messages}\n",
    "    query: {query}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"messages\", \"query\"])\n",
    "llm = OpenAIChat(temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_results(query, limit=50):\n",
    "    query_emb = generator.encode_messages(query)\n",
    "\n",
    "    results = index.query(\n",
    "      vector=query_emb.tolist(),\n",
    "      top_k=limit,\n",
    "      include_values=False,\n",
    "      include_metadata=True\n",
    "    )\n",
    "\n",
    "    messages = []\n",
    "    for item in results[\"matches\"]:\n",
    "        # print(f\"\\nscore {item['score']}\")\n",
    "        # print(item[\"metadata\"][\"clean_message\"])\n",
    "        messages.append(item[\"metadata\"][\"clean_message\"])\n",
    "\n",
    "    return messages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is good about this project?\"\n",
    "messages = search_results(query)\n",
    "inputs = [{\"message\": msg} for _, msg in zip(range(len(messages)), messages)]\n",
    "result = chain.run({\"messages\":inputs, \"query\":query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what do users complain about this project?\"\n",
    "messages = search_results(query)\n",
    "inputs = [{\"index\": i, \"message\": msg} for i, msg in zip(range(len(messages)), messages)]\n",
    "result = chain.run({\"messages\":inputs, \"query\":query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the open-source embedding function\n",
    "hf_embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# comput embeddings and load to chroma\n",
    "db = Chroma.from_documents(docs, hf_embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to query\n",
    "def search_db(db_client, query: str, top_k = 100):\n",
    "    docs = db_client.similarity_search(query, k=top_k)\n",
    "\n",
    "    # print results\n",
    "    for item in docs[:5]:\n",
    "        print(f\"\\n{item.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fosho\n",
      "\n",
      "seems like they 'RMI'  really FOMO'ing for this,  especially after reading the\n",
      "\n",
      "Hellyea\n",
      "\n",
      "saoyem Nice Francesco\n",
      "\n",
      "zealy\n"
     ]
    }
   ],
   "source": [
    "query = \"fomo\"\n",
    "search_db(db, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "client = Chroma.from_documents(\n",
    "    docs, \n",
    "    embedding_function, \n",
    "    client=persistent_client, \n",
    "    collection_name = f\"embeddings_collection_{channel_id[1:]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- User_1853540265: A coinbase listing would be bullish\n",
      "- User_6010276849: In a bear season as well this,  not sure there will be effect. Listing sometimes has been o do with the right timing as well. The hype is there, you list and boom up to the sky.\n",
      "\n",
      "- User_1460230397: We're thrilled to announce that the @xenergyweb Crowdloan on @Polkadot\n",
      " is now live! Join Energy Web in shaping the energy future and contribute.\n",
      "\n",
      "For more information about the Crowdloan, visit: https://crowdloan.energywebx.com\n",
      "\n",
      "Like and Retweet here: https://twitter.com/energywebx/status/1698820250643411030\n",
      "- User_5986732143: This crowdloan went so well!!! Cannot believe it‚Äôs a bear market at all.\n",
      "\n",
      "- User_1618131036: Another week went by. Hopefully the crypto market will recover soon\n",
      "- User_5418407519: I hope soo , we have endure bearish for a long time .\n",
      "\n",
      "- User_530622263: We are fortunate to be aware of such a great project during the last months of the bear market. A good time to dollar cost average IMO.\n",
      "- User_6448580728: Total agree\n",
      "\n",
      "- User_5454456997: Why day by day price go down?\n",
      "- User_6010276849: Happening to all it's the bear season, the best you can do for yourself mate is to wait for the bull run\n"
     ]
    }
   ],
   "source": [
    "query = \"bearish\"\n",
    "search_db(client, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-playground-K_szDW0O-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
